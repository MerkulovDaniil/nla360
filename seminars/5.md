---
title: Линейные системы. Собственные векторы и собственные значения. PageRank.
author: Даня Меркулов
institute: МФТИ. AI360
format: 
    beamer:
        pdf-engine: xelatex
        aspectratio: 169
        fontsize: 9pt
        section-titles: true
        incremental: true
        include-in-header: ../files/xeheader.tex  # Custom LaTeX commands and preamble
header-includes:
  - \newcommand{\bgimage}{../files/back4.jpeg}
---

# Линейные системы


## Матричные разложения и линейные системы

В задаче наименьших квадратов (aka линейной регрессии) мы имеем измерения $X \in \mathbb{R}^{m \times n}$ и $y \in \mathbb{R}^{m}$ и ищем вектор $\theta \in \mathbb{R}^{n}$ такой, что $X \theta$ близок к $y$. Близость определяется как сумма квадратов разностей: 
$$ 
\sum\limits_{i=1}^m (x_i^\top \theta - y_i)^2 \qquad \|X \theta - y\|^2_2 \to \min_{\theta \in \mathbb{R}^{n}} \qquad X \theta^* = y
$$

![Illustration of linear system aka least squares](lls_idea.pdf)

## Матричные разложения и линейные системы

### Moore–Penrose inverse
Если матрица $X$ относительно мала, мы можем записать и вычислить точное решение:

$$
\theta^* = (X^\top X)^{-1} X^\top y = X^\dagger y, 
$$

. . .

где $X^\dagger$ называется [псевдо-обратной](https://en.wikipedia.org/wiki/Moore%E2%80%93Penrose_inverse) матрицей. Однако, этот подход возводит в квадрат число обусловленности задачи, что может быть проблемой для больших и плохо обусловленных задач. 

. . .

### QR разложение
Для любой матрицы $X \in \mathbb{R}^{m \times n}$ существует QR разложение:

$$
X = Q \cdot R,
$$

. . .

где  $Q$ - ортогональная матрица (ее столбцы ортогональные единичные векторы) и $R$ - верхняя треугольная матрица. Важно отметить, что поскольку $Q^{-1} = Q^\top$, мы имеем:

$$
QR\theta = y \quad \longrightarrow \quad R \theta = Q^\top y
$$

Теперь процесс нахождения $\theta$ состоит из двух шагов:

1. Найдите QR разложение $X$.
1. Решите треугольную систему $R \theta = Q^\top y$, которая треугольная и, следовательно, легко решаемая.

## Матричные разложения и линейные системы

### Разложение Холецкого
Для любой положительно определенной матрицы $A \in \mathbb{R}^{n \times n}$ существует разложение Холецкого:

$$
X^\top X = A = L^\top \cdot L,
$$

где  $L$ - нижняя треугольная матрица. Мы имеем:

$$
L^\top L\theta = y \quad \longrightarrow \quad L^\top z_\theta = y
$$

Теперь процесс нахождения $\theta$ состоит из двух шагов:

1. Найдите разложение Холецкого $X^\top X$.
1. Найдите $z_\theta = L\theta$ путем решения треугольной системы $L^\top z_\theta = y$
1. Найдите $\theta$ путем решения треугольной системы $L\theta = z_\theta$

Обратите внимание, что в этом случае ошибка пропорциональна квадрату числа обусловленности.

## Матричные разложения и линейные системы

![Illustration](lls_times.pdf){width=78%}

## Число обусловленности $\varkappa$

[![](condition_number_gd.pdf)](https://fmin.xyz/docs/visualizations/condition_number_gd.mp4)

## Матричные разложения и линейные системы

![Illustration](non_linear_fit.pdf){width=78%}