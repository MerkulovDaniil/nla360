<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.41">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Lecture 13: Great Iterative Methods</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../favicon.svg" rel="icon" type="image/svg+xml">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-48ffa3e5b9d089919c6712c39e5b00f2.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-7f2a93ce03cd03d77aaf1c7855d4b88b.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>
<script src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/copy-tex.min.js" integrity="sha384-ww/583aHhxWkz5DEVn6OKtNiIaLi2iBRNZXfJRiY1Ai7tnJ9UXpEsyvOITVpTl4A" crossorigin="anonymous"></script>

  <script>window.backupDefine = window.define; window.define = undefined;</script><script src="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css">

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<meta property="og:title" content="Lecture 13: Great Iterative Methods">
<meta property="og:description" content="">
<meta property="og:image" content="https://nla360.fmin.xyz/lectures/lecture-13/slide_rule.jpg">
<meta name="twitter:title" content="Lecture 13: Great Iterative Methods">
<meta name="twitter:description" content="">
<meta name="twitter:image" content="https://nla360.fmin.xyz/lectures/lecture-13/slide_rule.jpg">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../../logo.svg" alt="nla360.fmin.xyz" class="navbar-logo">
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <span class="nav-link">
<span class="menu-text">program.md</span>
    </span>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../projects.html"> 
<span class="menu-text">üìΩÔ∏è –ü—Ä–æ–µ–∫—Ç—ã</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools tools-wide">
    <a href="https://github.com/MerkulovDaniil/nla360" title="" class="quarto-navigation-tool px-1" aria-label=""><i class="bi bi-github"></i></a>
    <a href="https://www.youtube.com/@fmin" title="" class="quarto-navigation-tool px-1" aria-label=""><i class="bi bi-youtube"></i></a>
    <a href="https://t.me/nla360" title="" class="quarto-navigation-tool px-1" aria-label=""><i class="bi bi-telegram"></i></a>
    <a href="https://classroom.google.com/c/NzU0NjE2Njg1Mzk3" title="" class="quarto-navigation-tool px-1" aria-label=""><i class="bi bi-person-workspace"></i></a>
    <a href="" title="" class="quarto-navigation-tool px-1" aria-label=""><i class="bi bi-table"></i></a>
    <a href="https://fmin.xyz" title="" class="quarto-navigation-tool px-1" aria-label=""><i class="bi bi-gem"></i></a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block"></header>

<header id="title-block-header">
</header>


<section id="previous-lecture" class="level3">
<h3 class="anchored" data-anchor-id="previous-lecture">Previous lecture</h3>
<ul>
<li>Concept of <strong>iterative methods</strong> for linear systems:
<ul>
<li>Richardson iteration and its convergence</li>
<li>Chebyshev iteration</li>
</ul></li>
</ul>
</section>
<section id="plan-for-this-part-of-class" class="level3">
<h3 class="anchored" data-anchor-id="plan-for-this-part-of-class">Plan for this part of class</h3>
<ul>
<li>Lanczos and Arnoldi orthogonalization of Krylov subspaces, optimality result for Krylov subspaces</li>
<li>Main iterative methods: conjugate gradient, GMRES, etc</li>
<li>Convergence estimates</li>
</ul>
</section>
<section id="solution-of-linear-systems-and-minimization-of-functionals" class="level2">
<h2 class="anchored" data-anchor-id="solution-of-linear-systems-and-minimization-of-functionals">Solution of linear systems and minimization of functionals</h2>
<ul>
<li>Instead of solving a linear system, we can minimize the <strong>residual:</strong></li>
</ul>
<p><span class="math display">R(x) = \Vert A x - f \Vert^2_2.</span></p>
<ul>
<li>The condition <span class="math inline">\nabla R(x) = 0</span> gives</li>
</ul>
<p><span class="math display">A^* A x = A^* f,</span></p>
<p>thus it has squared condition number, so direct minimization of the residual by standard optimization methods is rarely used.</p>
<ul>
<li>For the symmetric positive definite case there is a much simpler functional.</li>
</ul>
</section>
<section id="energy-functional" class="level2">
<h2 class="anchored" data-anchor-id="energy-functional">Energy functional</h2>
<p>Let <span class="math inline">A = A^* &gt; 0</span>, then the following functional</p>
<p><span class="math display">\Phi(x) = (Ax, x)  - 2(f, x)</span></p>
<p>is called <strong>energy functional</strong>.</p>
<section id="properties-of-energy-functional" class="level3">
<h3 class="anchored" data-anchor-id="properties-of-energy-functional">Properties of energy functional</h3>
<ul>
<li>It is strictly convex (check!)</li>
</ul>
<p><span class="math display"> \Phi(\alpha x + (1 - \alpha)y) &lt; \alpha \Phi(x) + (1 - \alpha) \Phi(y)</span></p>
<ul>
<li><p>Since it is strictly convex, it has unique local minimum, which is also global</p></li>
<li><p>Its global minimum <span class="math inline">x_*</span> satisfies</p></li>
</ul>
<p><span class="math display">A x_* = f.</span></p>
<p>Indeed,</p>
<p><span class="math display">\nabla \Phi = 2(Ax - f).</span></p>
<p>and the first order optimality condition <span class="math inline">\nabla \Phi (x_*) = 0</span> yields</p>
<p><span class="math display">A x_* = f.</span></p>
</section>
</section>
<section id="approximation-of-the-solution-by-a-subspace" class="level2">
<h2 class="anchored" data-anchor-id="approximation-of-the-solution-by-a-subspace">Approximation of the solution by a subspace</h2>
<ul>
<li>Given a linear <span class="math inline">M</span>-dimensional subspace <span class="math inline">\{y_1, \dots, y_M\}</span>, we want to find an approximate solution in this basis, i.e.&nbsp;</li>
</ul>
<p><span class="math display">A x \approx f, \quad x = x_0 +  \sum_{k=1}^M c_k y_k,</span></p>
<p>where <span class="math inline">c</span> is the vector of coefficients.</p>
<ul>
<li>In the symmetric positive definite case we need to minimize</li>
</ul>
<p><span class="math display">(Ax, x) - 2(f, x)</span></p>
<p>subject to <span class="math display">x = x_0 + Y c,</span></p>
<p>where <span class="math inline">Y=[y_1,\dots,y_M]</span> is <span class="math inline">n \times M</span> and vector <span class="math inline">c</span> has length <span class="math inline">M</span>.</p>
<ul>
<li>Using the representation of <span class="math inline">x</span>, we have the following minimization for <span class="math inline">c</span>:</li>
</ul>
<p><span class="math display">\widehat{\Phi}(c) = (A Y c, Y c) + 2 (Y^*Ax_0, c) - 2(f, Y c) = (Y^* A Y c, c) - 2(Y^* (f - Ax_0), c).</span></p>
<ul>
<li>Note that this is the same functional, but for the <strong>Galerkin projection</strong> of <span class="math inline">A</span></li>
</ul>
<p><span class="math display">Y^* A Y c = Y^* (f - Ax_0) = Y^* r_0,</span></p>
<p>which is an <span class="math inline">M \times M</span> linear system with symmetric positive definite matrix if <span class="math inline">Y</span> has full column rank.</p>
<p>But how to choose <span class="math inline">Y</span>?</p>
</section>
<section id="selection-of-the-subspace-random-projection" class="level2">
<h2 class="anchored" data-anchor-id="selection-of-the-subspace-random-projection">Selection of the subspace: random projection</h2>
<ul>
<li>We can generate <span class="math inline">Y</span> with random numbers and then orthogonalize</li>
<li>What quality of <span class="math inline">x</span> will we get in this case?</li>
<li>How the derived quality relates to the conditioning of the matrix?</li>
<li>Selection of the proper random matrix is important topic in dimensionality reduction theory and relates to <a href="http://cs-people.bu.edu/evimaria/cs565/kdd-rp.pdf">random projection</a> approach</li>
</ul>
<div id="cell-9" class="cell" data-slideshow="{&quot;slide_type&quot;:&quot;slide&quot;}" data-execution_count="2">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>n <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>A <span class="op">=</span> np.random.randn(n, n)</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>Q, _ <span class="op">=</span> np.linalg.qr(A)</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>k <span class="op">=</span> <span class="dv">70</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>A <span class="op">=</span> Q.T <span class="op">@</span> np.diag([<span class="fl">1e-6</span>] <span class="op">*</span> k <span class="op">+</span> <span class="bu">list</span>(np.random.rand(n<span class="op">-</span>k))) <span class="op">@</span> Q</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>x_true <span class="op">=</span> np.random.randn(n)</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>rhs <span class="op">=</span> A <span class="op">@</span> x_true</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>M <span class="op">=</span> n <span class="op">-</span> k</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>Y <span class="op">=</span> np.random.randn(n, M)</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>A_proj <span class="op">=</span> Y.T <span class="op">@</span> A <span class="op">@</span> Y</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>rhs_proj <span class="op">=</span> Y.T <span class="op">@</span> rhs</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(A_proj.shape)</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>c <span class="op">=</span> np.linalg.solve(A_proj, rhs_proj)</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>x_proj <span class="op">=</span> Y <span class="op">@</span> c</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(np.linalg.norm(A <span class="op">@</span> x_proj <span class="op">-</span> rhs) <span class="op">/</span> np.linalg.norm(rhs))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>(30, 30)
0.00044969726264993147</code></pre>
</div>
</div>
</section>
<section id="selection-of-the-subspace-krylov-subspace" class="level2">
<h2 class="anchored" data-anchor-id="selection-of-the-subspace-krylov-subspace">Selection of the subspace: Krylov subspace</h2>
<p>In the Krylov subspace we generate the whole subspace from a single vector <span class="math inline">r_0 = f - Ax_0</span>:</p>
<p><span class="math display">y_0\equiv k_0 = r_0, \quad y_1\equiv k_1 = A r_0, \quad y_2\equiv k_2 = A^2 r_0, \ldots, \quad y_{M-1}\equiv k_{M-1} = A^{M-1} r_0.</span></p>
<p>This gives the <strong>Krylov subpace</strong> of the <span class="math inline">M</span>-th order</p>
<p><span class="math display">\mathcal{K}_M(A, r_0) = \mathrm{Span}(r_0, Ar_0, \ldots, A^{M-1} r_0).</span></p>
<ul>
<li>It is known to be quasi-optimal space given only matrix-vector product operation.</li>
<li>Key reference here is ‚ÄúOn the numerical solution of equation by which are determined in technical problems the frequencies of small vibrations of material systems‚Äù, A. N. Krylov, 1931, <a href="http://www.mathnet.ru/links/a2431bc65c0764da9a1ae95c73f741f6/im5215.pdf">text in russian</a></li>
</ul>
</section>
<section id="solution-x_-lies-in-the-krylov-subspace-x_-in-mathcalk_na-f" class="level2">
<h2 class="anchored" data-anchor-id="solution-x_-lies-in-the-krylov-subspace-x_-in-mathcalk_na-f">Solution <span class="math inline">x_*</span> lies in the Krylov subspace: <span class="math inline">x_* \in \mathcal{K}_n(A, f)</span></h2>
<ul>
<li>According to <a href="https://en.wikipedia.org/wiki/Cayley%E2%80%93Hamilton_theorem">Cayley‚ÄìHamilton theorem</a>: <span class="math inline">p(A) = 0</span>, where <span class="math inline">p(\lambda) = \det(A - \lambda I)</span></li>
<li><span class="math inline">p(A)f = A^nf + a_1A^{n-1}f + \ldots + a_{n-1}Af + a_n f = 0</span></li>
<li><span class="math inline">A^{-1}p(A)f = A^{n-1}f + a_1A^{n-2}f + \ldots + a_{n-1}f + a_nA^{-1}f = 0</span></li>
<li><span class="math inline">x_* = A^{-1}f = -\frac{1}{a_n}(A^{n-1}f + a_1A^{n-2}f + \ldots + a_{n-1}f)</span></li>
<li>Thus, <span class="math inline">x_* \in \mathcal{K}_n(A, f)</span></li>
</ul>
</section>
<section id="ill-conditioned-of-the-natural-basis" class="level2">
<h2 class="anchored" data-anchor-id="ill-conditioned-of-the-natural-basis">Ill-conditioned of the natural basis</h2>
<p>The natural basis in the Krylov subspace is very <strong>ill-conditioned</strong>, since</p>
<p><span class="math display">k_i = A^i r_0 \rightarrow \lambda_\max^i v,</span></p>
<p>where <span class="math inline">v</span> is the eigenvector, corresponding to the maximal eigenvalue of <span class="math inline">A</span>, i.e.&nbsp;<span class="math inline">k_i</span> become more and more collinear for large <span class="math inline">i</span>.</p>
<div id="cell-13" class="cell" data-slideshow="{&quot;slide_type&quot;:&quot;slide&quot;}" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> scipy.sparse <span class="im">as</span> spsp</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>matplotlib inline</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>n <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>ex <span class="op">=</span> np.ones(n)<span class="op">;</span></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>A <span class="op">=</span> spsp.spdiags(np.vstack((<span class="op">-</span>ex,  <span class="dv">2</span><span class="op">*</span>ex, <span class="op">-</span>ex)), [<span class="op">-</span><span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>], n, n, <span class="st">'csr'</span>)<span class="op">;</span> </span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>f <span class="op">=</span> np.ones(n)</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>x0 <span class="op">=</span> np.random.randn(n)</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>subspace_order <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>krylov_vectors <span class="op">=</span> np.zeros((n, subspace_order))</span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>krylov_vectors[:, <span class="dv">0</span>] <span class="op">=</span> f <span class="op">-</span> A.dot(x0)</span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, subspace_order):</span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>    krylov_vectors[:, i] <span class="op">=</span> A.dot(krylov_vectors[:, i<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>s <span class="op">=</span> np.linalg.svd(krylov_vectors, compute_uv<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Condition number = </span><span class="sc">{}</span><span class="st">"</span>.<span class="bu">format</span>(s.<span class="bu">max</span>() <span class="op">/</span> s.<span class="bu">min</span>()))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Condition number = 497674309.99072236</code></pre>
</div>
</div>
<p><strong>Solution:</strong> Compute orthogonal basis in the Krylov subspace.</p>
</section>
<section id="good-basis-in-a-krylov-subspace" class="level2">
<h2 class="anchored" data-anchor-id="good-basis-in-a-krylov-subspace">Good basis in a Krylov subspace</h2>
<p>In order to have stability, we first orthogonalize the vectors from the Krylov subspace using <strong>Gram-Schmidt</strong> orthogonalization process (or, QR-factorization).</p>
<p><span class="math display">K_j = \begin{bmatrix} r_0 &amp; Ar_0 &amp; A^2 r_0 &amp; \ldots &amp; A^{j-1} r_0\end{bmatrix} = Q_j R_j, </span></p>
<p>and the solution will be approximated as</p>
<p><span class="math display">x \approx x_0 + Q_j c.</span></p>
</section>
<section id="short-way-to-arnoldi-relation" class="level2">
<h2 class="anchored" data-anchor-id="short-way-to-arnoldi-relation">Short way to Arnoldi relation</h2>
<p><strong>Statement.</strong> The Krylov matrix <span class="math inline">K_j</span> satisfies an important recurrent relation (called <strong>Arnoldi relation</strong>)</p>
<p><span class="math display">A Q_j = Q_j H_j + h_{j, j-1} q_j e^{\top}_{j-1},</span></p>
<p>where <span class="math inline">H_j</span> is upper Hessenberg, and <span class="math inline">Q_{j+1} = [q_0,\dots,q_j]</span> has orthogonal columns that spans columns of <span class="math inline">K_{j+1}</span>.</p>
<p>Let us prove it (consider <span class="math inline">j = 3</span> for simplicity):</p>
<p><span class="math display">A \begin{bmatrix} k_0 &amp; k_1 &amp; k_2 \end{bmatrix} = \begin{bmatrix} k_1 &amp; k_2 &amp; k_3 \end{bmatrix} = \begin{bmatrix} k_0 &amp; k_1 &amp; k_2 \end{bmatrix} \begin{bmatrix} 0 &amp; 0 &amp; \alpha_0 \\ 1 &amp; 0  &amp; \alpha_1 \\ 0 &amp; 1  &amp; \alpha_2 \\ \end{bmatrix} + \begin{bmatrix} 0 &amp; 0 &amp; k_3  - \alpha_0 k_0 - \alpha_1 k_1 - \alpha_2 k_2 \end{bmatrix}, </span></p>
<p>where <span class="math inline">\alpha_s</span> will be selected later. Denote <span class="math inline">\widehat{k}_3 = k_3  - \alpha_0 k_0 - \alpha_1 k_1 - \alpha_2 k_2</span>.</p>
<p>In the matrix form,</p>
<p><span class="math display">A K_3 = K_3 Z + \widehat k_3 e^{\top}_2,</span></p>
<p>where <span class="math inline">Z</span> is the <strong>lower shift</strong> matrix with the last column <span class="math inline">(\alpha_0,\alpha_1,\alpha_2)^T</span>, and <span class="math inline">e_2</span> is the last column of the identity matrix.</p>
<p>Let</p>
<p><span class="math display">K_3 = Q_3 R_3</span></p>
<p>be the QR-factorization. Then,</p>
<p><span class="math display">A Q_3 R_3 = Q_3 R_3 Z + \widehat{k}_3 e^{\top}_2,</span></p>
<p><span class="math display"> A Q_3 = Q_3 R_3 Z R_3^{-1} + \widehat{k}_3 e^{\top}_2 R_3^{-1}.</span></p>
<p>Note that</p>
<p><span class="math display">e^{\top}_2 R_3^{-1} = \begin{bmatrix} 0 &amp; 0 &amp; 1 \end{bmatrix} \begin{bmatrix} * &amp; * &amp; * \\ 0 &amp; * &amp; * \\ 0 &amp; 0 &amp; * \end{bmatrix}  = \gamma e^{\top}_2,</span> and</p>
<p><span class="math display">R_3 Z R_3^{-1} = \begin{bmatrix} * &amp; * &amp; * \\* &amp; * &amp; * \\  0 &amp; * &amp; * \\ \end{bmatrix},</span></p>
<p>in the general case it will be an <strong>upper Hessenberg matrix</strong> <span class="math inline">H</span>, i.e.&nbsp;a matrix that</p>
<p><span class="math display">H_{ij} = 0, \quad \mbox{if } i &gt; j + 1.</span></p>
</section>
<section id="almost-arnoldi-relation" class="level2">
<h2 class="anchored" data-anchor-id="almost-arnoldi-relation">(Almost) Arnoldi relation</h2>
<p>Let <span class="math inline">Q_j</span> be the orthogonal basis in the Krylov subspace, then we have almost the Arnoldi relation</p>
<p><span class="math display">A Q_j = Q_j H_j +  \gamma\widehat{k}_j e^{\top}_{j-1},</span></p>
<p>where <span class="math inline">H_j</span> is an upper Hessenberg matrix, and</p>
<p><span class="math display">\widehat{k}_j = k_j - \sum_{s=0}^{j-1} \alpha_s k_s.</span></p>
<p>We select <span class="math inline">\alpha_s</span> in such a way that</p>
<p><span class="math display">Q^*_j \widehat{k}_j = 0.</span></p>
<p>Then, <span class="math inline">\widehat{k}_j = h_{j, j-1} q_j,</span> where <span class="math inline">q_j</span> is the last column of <span class="math inline">Q_{j+1}</span>.</p>
</section>
<section id="arnoldi-relation-final-formula" class="level2">
<h2 class="anchored" data-anchor-id="arnoldi-relation-final-formula">Arnoldi relation: final formula</h2>
<p>We have</p>
<p><span class="math display">A Q_j = Q_j H_j + h_{j, j-1} q_j e^{\top}_{j-1}.</span></p>
<ul>
<li><p>This is the crucial formula for the efficient generation of such subspaces.</p></li>
<li><p>For non-symmetric case, it is just modified Gram-Schmidt.</p></li>
<li><p>For the symmetric case, we have a much simpler form (Lanczos process).</p></li>
</ul>
</section>
<section id="lanczos-process" class="level2">
<h2 class="anchored" data-anchor-id="lanczos-process">Lanczos process</h2>
<p>If <span class="math inline">A = A^*</span>, then</p>
<p><span class="math display">Q^*_j A Q_j = H_j, </span></p>
<p>thus <span class="math inline">H_j</span> is hermitian, and thus it is <strong>tridiagonal</strong>, <span class="math inline">H_j = T_j</span>.</p>
<p>This gives a short-term recurrence relation to generate the Arnoldi vectors <span class="math inline">q_j</span> without <strong>full</strong> orthogonalization.</p>
</section>
<section id="lanczos-process-2" class="level2">
<h2 class="anchored" data-anchor-id="lanczos-process-2">Lanczos process (2)</h2>
<p><span class="math display"> A Q_j = Q_j T_j + t_{j, j-1} q_j e^{\top}_{j-1}.</span></p>
<p>In order to get <span class="math inline">q_j</span>, we need to compute just the last column of</p>
<p><span class="math display">t_{j, j-1} q_j = (A Q_j - Q_j T_j) e_{j-1} = A q_{j-1} - t_{j-1, j-1} q_{j-1} - t_{j-2, j-1} q_{j-2}. </span></p>
<p>The coefficients <span class="math inline">\alpha_j = t_{j-1, j-1}</span> and <span class="math inline">\beta_j = t_{j-2, j-1}</span> can be recovered from orthogonality constraints</p>
<p><span class="math inline">(q_j, q_{j-1}) = 0, \quad (q_j, q_{j-2}) = 0</span></p>
<p><strong>All the other constraints will be satisfied automatically!!</strong></p>
<p>And we only need to store two vectors to get the new one.</p>
</section>
<section id="from-direct-lanczos-method-to-the-conjugate-gradient" class="level2">
<h2 class="anchored" data-anchor-id="from-direct-lanczos-method-to-the-conjugate-gradient">From direct Lanczos method to the conjugate gradient</h2>
<p>We can now get from the Lanczos recurrence to the famous <strong>conjugate gradient</strong> method.</p>
<p>We have for <span class="math inline">A = A^* &gt; 0</span></p>
<p><span class="math display">A Q_j = Q_j T_j + T_{j, j-1} q_j.</span></p>
<p>Recall that when we minimize energy functional in basis <span class="math inline">Y</span> we get a system <span class="math inline">Y^* A Y c = Y^* f,</span>. Here <span class="math inline">Y = Q_j</span>, so the approximate solution of <span class="math inline">Ax \approx f</span> with <span class="math inline">x_j = x_0 + Q_j c_j</span> can be found by solving a small system</p>
<p><span class="math display">Q^*_j A Q_j c_j = T_j c_j = Q^*_j r_0 .</span></p>
<p>Since <span class="math inline">f</span> is the first Krylov subspace, then <strong>Note!!!</strong> (recall what the first column in <span class="math inline">Q_j</span> is)</p>
<p><span class="math display">Q^*_j r_0  = \Vert r_0 \Vert_2 e_0 = \gamma e_0.</span></p>
<p>We have a tridiagonal system of equations for <span class="math inline">c</span>:</p>
<p><span class="math display">T_j c_j = \gamma e_0</span></p>
<p>and <span class="math inline">x_j = Q_j c_j</span>.</p>
<p>We could stop at this point, but we want short recurrent formulas instead of solving linear system with matrix <span class="math inline">T_j</span> at each step.</p>
<p><strong>Derivation of the following update formulas is not required on the oral exam!</strong></p>
<ul>
<li><p>Since <span class="math inline">A</span> is positive definite, <span class="math inline">T_j</span> is also positive definite, and it allows an LU decomposition</p></li>
<li><p><span class="math inline">T_j = L_j U_j</span>, where <span class="math inline">L_j</span> is a bidiagonal matrix with ones on the diagonal, <span class="math inline">U_j</span> is a upper bidiagonal matrix.</p></li>
</ul>
<p><span class="math display"> T_j = \begin{bmatrix} a_1 &amp; b_1 &amp;  &amp; \\ b_1 &amp; a_2 &amp; b_2 &amp; \\ &amp; \ddots &amp; \ddots &amp; \ddots &amp; \\ &amp; &amp; b_{j-1} &amp; a_{j-1} &amp; b_j \\ &amp; &amp; &amp; b_j &amp; a_j \end{bmatrix} = \begin{bmatrix} 1 &amp; &amp;  &amp; \\ c_1 &amp; 1 &amp;  &amp; \\ &amp; \ddots &amp; \ddots &amp;  &amp; \\ &amp; &amp; c_{j-1} &amp; 1 &amp; \\ &amp; &amp; &amp; c_j &amp; 1 \end{bmatrix} \begin{bmatrix} d_1 &amp; b_1 &amp;  &amp; \\ &amp; d_1 &amp; b_2 &amp; \\ &amp; &amp; \ddots &amp; \ddots &amp; \\ &amp; &amp; &amp; d_{j-1} &amp; b_j \\ &amp; &amp; &amp; &amp; d_j \end{bmatrix} </span></p>
<ul>
<li><p>We need to define one subdiagonal in <span class="math inline">L</span> (with elements <span class="math inline">c_1, \ldots, c_{j-1}</span>), main diagonal of <span class="math inline">U_j</span> (with elements <span class="math inline">d_0, \ldots, d_{j-1}</span> and superdiagonal of <span class="math inline">U_j</span> (with elements <span class="math inline">b_1, \ldots, b_{j-1}</span>).</p></li>
<li><p>They have convenient recurrences:</p></li>
</ul>
<p><span class="math display">c_i = b_i/d_{i-1}, \quad d_i = \begin{cases} a_1, &amp; \mbox{if } i = 1, \\
a_i - c_i b_i, &amp; \mbox{if } i &gt; 1. \end{cases}</span></p>
<ul>
<li>For the solution we have</li>
</ul>
<p><span class="math display">x_j = Q_j T^{-1}_j \gamma e_0  = \gamma Q_j (L_j U_j)^{-1} e_0  = \gamma Q_j U^{-1}_j L^{-1}_j e_0.</span></p>
<ul>
<li>We introduce two new quantities:</li>
</ul>
<p><span class="math display">P_j = Q_j U^{-1}_j, \quad z_j = \gamma L^{-1}_j e_0.</span></p>
<ul>
<li>Now we have the following equation for <span class="math inline">x_j</span>:</li>
</ul>
<p><span class="math display"> x_j = P_j z_j</span></p>
<ul>
<li>Due to the recurrence relations, we have</li>
</ul>
<p><span class="math display">P_j = \begin{bmatrix} P_{j-1} &amp; p_j \end{bmatrix}, </span></p>
<p>and</p>
<p><span class="math display">z_j = \begin{bmatrix} z_{j-1} \\ \xi_{j} \end{bmatrix}.</span></p>
<ul>
<li>For <span class="math inline">p_j</span> and <span class="math inline">\xi_j</span> we have short-term recurrence relations (due to bidiagonal structure)</li>
</ul>
<p><span class="math display">p_j = \frac{1}{d_j}\left(q_j - b_j p_{j-1} \right), \quad \xi_j = -c_j \xi_{j-1}.</span></p>
<ul>
<li>Thus, we arrive at short-term recurrence for <span class="math inline">x_j</span>:</li>
</ul>
<p><span class="math display">x_j = P_j z_j = P_{j-1} z_{j-1} + \xi_j p_j = x_{j-1} + \xi_j p_j.</span></p>
<p>and <span class="math inline">q_j</span> are found from the Lanczos relation (see slides above).</p>
<ul>
<li>This method for solving linear systems is called a <strong>direct Lanczos method</strong>. It is closely related to the conjugate gradient method.</li>
</ul>
</section>
<section id="direct-lanczos-method" class="level2">
<h2 class="anchored" data-anchor-id="direct-lanczos-method">Direct Lanczos method</h2>
<p>We have the direct Lanczos method, where we store</p>
<p><span class="math display">p_{j-1}, q_j, x_{j-1}</span> to get a new estimate of <span class="math inline">x_j</span>.</p>
<p>The main problem is with <span class="math inline">q_j</span>: we have the three-term recurrence, but in the floating point arithmetic the orthogonality is can be lost, leading to numerical errors.</p>
<p>Let us do some demo.</p>
<div id="cell-24" class="cell" data-slideshow="{&quot;slide_type&quot;:&quot;slide&quot;}" data-execution_count="6">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>matplotlib inline</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> scipy <span class="im">as</span> sp</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> scipy.sparse <span class="im">as</span> spsp</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.sparse <span class="im">import</span> csc_matrix</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>n <span class="op">=</span> <span class="dv">128</span></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>ex <span class="op">=</span> np.ones(n)<span class="op">;</span></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>A <span class="op">=</span> spsp.spdiags(np.vstack((ex,  <span class="op">-</span><span class="dv">2</span><span class="op">*</span>ex, ex)), [<span class="op">-</span><span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>], n, n, <span class="st">'csr'</span>)<span class="op">;</span> </span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>rhs <span class="op">=</span> np.ones(n)</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>nit <span class="op">=</span> <span class="dv">64</span></span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>q1 <span class="op">=</span> rhs<span class="op">/</span>np.linalg.norm(rhs)</span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>q2 <span class="op">=</span> A.dot(q1)</span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>q2 <span class="op">=</span> q2 <span class="op">-</span> np.dot(q2, q1)<span class="op">*</span>q1</span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>q2 <span class="op">=</span> q2<span class="op">/</span>np.linalg.norm(q2)</span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>qall <span class="op">=</span> [q1, q2]</span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(nit):</span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a>    qnew <span class="op">=</span> A.dot(qall[<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a>    qnew <span class="op">=</span> qnew <span class="op">-</span> np.dot(qnew, qall[<span class="op">-</span><span class="dv">1</span>])<span class="op">*</span>qall[<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a>    qnew <span class="op">=</span> qnew<span class="op">/</span>np.linalg.norm(qnew)</span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a>    qnew <span class="op">=</span> qnew <span class="op">-</span> np.dot(qnew, qall[<span class="op">-</span><span class="dv">2</span>])<span class="op">*</span>qall[<span class="op">-</span><span class="dv">2</span>]</span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a>    qnew <span class="op">=</span> qnew<span class="op">/</span>np.linalg.norm(qnew)</span>
<span id="cb5-25"><a href="#cb5-25" aria-hidden="true" tabindex="-1"></a>    qall.append(qnew)</span>
<span id="cb5-26"><a href="#cb5-26" aria-hidden="true" tabindex="-1"></a>qall_mat <span class="op">=</span> np.vstack(qall).T</span>
<span id="cb5-27"><a href="#cb5-27" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(np.linalg.norm(qall_mat.T.dot(qall_mat) <span class="op">-</span> np.eye(qall_mat.shape[<span class="dv">1</span>])))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>1.9605915654183865</code></pre>
</div>
</div>
</section>
<section id="conjugate-gradient-method" class="level2">
<h2 class="anchored" data-anchor-id="conjugate-gradient-method">Conjugate gradient method</h2>
<p>Instead of <span class="math inline">q_j</span> (last vector in the modified Gram-Schmidt process), it is more convenient to work with the <strong>residual</strong></p>
<p><span class="math display">r_j = f - A x_j.</span></p>
<p>The resulting recurrency has the form</p>
<p><span class="math inline">x_j = x_{j-1} + \alpha_{j-1} p_{j-1}</span></p>
<p><span class="math inline">r_j = r_{j-1} - \alpha_{j-1}  A p_{j-1}</span></p>
<p><span class="math inline">p_j = r_j + \beta_j p_{j-1}</span>.</p>
<p>Hence the name conjugate gradient: to the gradient <span class="math inline">r_j</span> we add a <strong>conjugate direction</strong> <span class="math inline">p_j</span>.</p>
<p>We have <strong>orthogonality</strong> of residuals (check!):</p>
<p><span class="math display">(r_i, r_j) = 0, \quad i \ne j</span></p>
<p>and <strong>A-orthogonality</strong> of conjugate directions (check!):</p>
<p><span class="math display"> (A p_i, p_j) = 0,</span></p>
<p>which can be checked from the definition.</p>
<p>The equations for <span class="math inline">\alpha_j</span> and <span class="math inline">\beta_j</span> can be now defined explicitly from these two properties.</p>
</section>
<section id="cg-final-formulas" class="level2">
<h2 class="anchored" data-anchor-id="cg-final-formulas">CG final formulas</h2>
<p>We have <span class="math inline">(r_{j}, r_{j-1}) = 0 = (r_{j-1} - \alpha_{j-1} A p_{j-1}, r_{j-1})</span>,</p>
<p>thus</p>
<p><span class="math display">\alpha_{j-1} = \frac{(r_{j-1}, r_{j-1})}{(A p_{j-1}, r_{j-1})} = \frac{(r_{j-1}, r_{j-1})}{(A p_{j-1}, p_{j-1} - \beta_{j-1}p_{j-2})} = \frac{(r_{j-1}, r_{j-1})}{(A p_{j-1}, p_{j-1})}.</span></p>
<p>In the similar way, we have</p>
<p><span class="math display">\beta_{j-1} = \frac{(r_j, r_j)}{(r_{j-1}, r_{j-1})}.</span></p>
<p>Recall that</p>
<p><span class="math inline">x_j = x_{j-1} + \alpha_{j-1} p_{j-1}</span></p>
<p><span class="math inline">r_j = r_{j-1} - \alpha_{j-1}  A p_{j-1}</span></p>
<p><span class="math inline">p_j = r_j + \beta_j p_{j-1}</span>.</p>
<p>Only one matrix-by-vector product per iteration.</p>
</section>
<section id="cg-derivation-overview" class="level2">
<h2 class="anchored" data-anchor-id="cg-derivation-overview">CG derivation overview</h2>
<ul>
<li>Want to find <span class="math inline">x_*</span> in Krylov subspace</li>
<li>But natural basis is ill-conditioned, therefore we need orthogonalization</li>
<li>Derive recurrent equation for sequential orthogonalization of the Krylov subspace basis
<ul>
<li>Arnoldi process for non-symmetric matrix</li>
<li>Lanczos process for symmetrix matrix</li>
</ul></li>
<li>Clever re-writing of these formulas gives short recurrence</li>
</ul>
</section>
<section id="some-history" class="level2">
<h2 class="anchored" data-anchor-id="some-history">Some history</h2>
<p>More details here: https://www.siam.org/meetings/la09/talks/oleary.pdf</p>
<p>When Hestenes worked on conjugate bases in 1936, he was advised by a Harvard professor that it was too obvious for publication - CG doesn‚Äôt work on slide rules. <img src="slide_rule.jpg"> - CG has little advantage over Gauss elimination for computation with calculators. - CG is not well suited for a room of human ‚Äúcomputers‚Äù ‚Äì too much data exchange. <img src="human_computers.jpg"></p>
</section>
<section id="properties-of-the-cg-method" class="level2">
<h2 class="anchored" data-anchor-id="properties-of-the-cg-method">Properties of the CG method</h2>
<ul>
<li><p>We need to store 3 vectors.</p></li>
<li><p>Since it generates <span class="math inline">A</span>-orthogonal sequence <span class="math inline">p_1, \ldots, p_N</span>, after <span class="math inline">n</span> steps it should stop (i.e., <span class="math inline">p_{N+1} = 0</span>.)</p></li>
<li><p>In practice it does not have this property in finite precision, thus after its invention in 1952 by Hestens and Stiefel it was labeled <strong>unstable</strong>.</p></li>
<li><p>In fact, it is a brilliant iterative method.</p></li>
</ul>
</section>
<section id="a-optimality" class="level2">
<h2 class="anchored" data-anchor-id="a-optimality"><span class="math inline">A</span>-optimality</h2>
<p>Energy functional can be written as</p>
<p><span class="math display">(Ax, x) - 2(f, x) = (A (x - x_*), (x - x_*)) - (Ax _*, x_*),</span></p>
<p>where <span class="math inline">A x_* = f</span>. Up to a constant factor,</p>
<p><span class="math display"> (A(x - x_*), (x -x_*)) = \Vert x - x_* \Vert^2_A</span></p>
<p>is the <strong>A-norm</strong> of the error.</p>
</section>
<section id="convergence" class="level2">
<h2 class="anchored" data-anchor-id="convergence">Convergence</h2>
<p>The CG method computes <span class="math inline">x_k</span> that minimizes the energy functional over the Krylov subspace, i.e.&nbsp;<span class="math inline">x_k = p(A)f</span>, where <span class="math inline">p</span> is a polynomial of degree <span class="math inline">k+1</span>, so</p>
<p><span class="math display">\Vert x_k - x_* \Vert_A  =  \inf\limits_{p} \Vert \left(p(A) - A^{-1}\right) f \Vert_A. </span></p>
<p>Using eigendecomposition of <span class="math inline">A</span> we have</p>
<p><span class="math display">A = U \Lambda U^*, \quad  g = U^* f,</span> and</p>
<p><span class="math inline">\Vert x - x_* \Vert^2_A = \displaystyle{\inf_p} \Vert \left(p(\Lambda) - \Lambda^{-1}\right) g \Vert_\Lambda^2 = \displaystyle{\inf_p}
\displaystyle{\sum_{i=1}^n} \frac{(\lambda_i p(\lambda_i) - 1)^2 g^2_i}{\lambda_i} = \displaystyle{\inf_{q, q(0) = 1}} \displaystyle{\sum_{i=1}^n} \frac{q(\lambda_i)^2 g^2_i}{\lambda_i}</span></p>
<p>Selection of the optimal <span class="math inline">q</span> depends on the eigenvalue distribution.</p>
</section>
<section id="absolute-and-relative-error" class="level2">
<h2 class="anchored" data-anchor-id="absolute-and-relative-error">Absolute and relative error</h2>
<p>We have</p>
<p><span class="math display">\Vert x - x_* \Vert^2_A \leq \sum_{i=1}^n \frac{g^2_i}{\lambda_i} \inf_{q, q(0)=1} \max_{j} q({\lambda_j})^2</span></p>
<p>The first term is just</p>
<p><span class="math display">\sum_{i=1}^n \frac{g^2_i}{\lambda_i} = (A^{-1} f, f) = \Vert x_* \Vert^2_A.</span></p>
<p>And we have relative error bound</p>
<p><span class="math display">\frac{\Vert x - x_* \Vert_A }{\Vert x_* \Vert_A} \leq \inf_{q, q(0)=1} \max_{j} |q({\lambda_j})|,</span></p>
<p>so if matrix has only 2 different eigenvalues, then there exists a polynomial of degree 2 such that <span class="math inline">q({\lambda_1}) =q({\lambda_2})=0</span>, so in this case CG converges in 2 iterations.</p>
<p><font color="red"></font></p><font color="red">
</font><ul><font color="red">
<li><p>If eigenvalues are clustered and there are <span class="math inline">l</span> outliers, then after first <span class="math inline">\mathcal{O}(l)</span> iterations CG will converge as if there are no outliers (and hence the effective condition number is smaller).</p></li>
</font><li><font color="red"></font><p><font color="red">The intuition behind this fact is that after <span class="math inline">\mathcal{O}(l)</span> iterations the polynomial has degree more than <span class="math inline">l</span> and thus is able to zero <span class="math inline">l</span> outliers. </font></p></li>
</ul>
<p>Let us find another useful upper-bound estimate of convergence. Since</p>
<p><span class="math display">
\inf_{q, q(0)=1} \max_{j} |q({\lambda_j})| \leq \inf_{q, q(0)=1} \max_{\lambda\in[\lambda_\min,\lambda_\max]} |q({\lambda})|
</span></p>
<p>The last term is just the same as for the Chebyshev acceleration, thus the same upper convergence bound holds:</p>
<p><span class="math display">\frac{\Vert x_k - x_* \Vert_A }{\Vert x_* \Vert_A} \leq \gamma \left( \frac{\sqrt{\mathrm{cond}(A)}-1}{\sqrt{\mathrm{cond}(A)}+1}\right)^k.</span></p>
</section>
<section id="finite-termination-clusters" class="level2">
<h2 class="anchored" data-anchor-id="finite-termination-clusters">Finite termination &amp; clusters</h2>
<ol type="1">
<li>If <span class="math inline">A</span> has only <span class="math inline">m</span> different eigenvalues, CG converges in <span class="math inline">m</span> iterations (proof in the blackboard).</li>
<li>If <span class="math inline">A</span> has <span class="math inline">m</span> ‚Äúclusters‚Äù of eigenvalues, CG converges cluster-by-cluster.</li>
</ol>
<p>As a result, better convergence than Chebyshev acceleration, but slightly higher cost per iteration.</p>
</section>
<section id="summary" class="level2">
<h2 class="anchored" data-anchor-id="summary">Summary</h2>
<p>CG is the method of choice for symmetric positive definite systems:</p>
<ol type="1">
<li><span class="math inline">\mathcal{O}(n)</span> memory</li>
<li>Square root of condition number in the estimates</li>
<li>Automatic ignoring of the outliers/clusters</li>
<li><span class="math inline">A</span>-optimality property</li>
</ol>
</section>
<section id="non-linear-conjugate-gradient-method" class="level2">
<h2 class="anchored" data-anchor-id="non-linear-conjugate-gradient-method">Non-linear conjugate gradient method</h2>
<ul>
<li>CG minimizes the energy functional, which is quadratic in <span class="math inline">x</span></li>
<li>CG formulas were used as starting point in developing methods to minimize arbitrary convex function</li>
<li>Most popular CG extensions (so-called non-linear CG method) are
<ul>
<li><a href="https://www.fing.edu.uy/inco/cursos/numerico/aln/hes_stief1952.pdf">Hestenes-Stiefel method</a></li>
<li><a href="http://www.numdam.org/article/M2AN_1969__3_1_35_0.pdf">Polak-Ribiere method</a> - original paper in French</li>
<li><a href="https://watermark.silverchair.com/070149.pdf?token=AQECAHi208BE49Ooan9kkhW_Ercy7Dm3ZL_9Cf3qfKAc485ysgAAAkMwggI_BgkqhkiG9w0BBwagggIwMIICLAIBADCCAiUGCSqGSIb3DQEHATAeBglghkgBZQMEAS4wEQQMiWM0crDA8bZ0Fj5HAgEQgIIB9tIM8xbxhkhniJQifurRLHIaOcnos9gvgBj8Lkc34eBUtUg4oYzjusGP_FZiHfpBoRnM409FFCs-Y5xxomumnGRQ8UIZJe7CPSmaCcSklAdwHN3Ja-fHfALctP68U3mGGeR11P8vlESoS7HZhZEmVhFb5m7jPk1ENZKLlq9CnVTz2n2bI3HPYCfDIo8ywd8RWo5gw6EwYnZ46l1ExES8AHMqlklpgzdupLhL6HxTzBEHd_qY4B2FjK4m4MpvdaX5imEnOD6YCwZMNC_qLzUdPxumcXl4oTRDyJp1kg_6PcGi98hE10InOp4aHJeIjl5FPJnuEFEBcv28asOq4vngp6N5d-4y1fpeoxcAe4d857TeLtQnGD6LlCAL_3Mh0lQ8iYLLfjw4b_V2jHEuSxKH3BalLPMS5KF2nGqqrzfbDs8x9jW-OlkeL_x68Zidv0rTHqTd0ww3kvSINDjgw6owPMLK9KxEWP5T-4dnu_kn-NXR1W0s52kUHFD1U9AWs5Zzh4RTVOXsdjGQciWzOO-XieLn8Aju-0P8mVEGjUDOjLDZtuPYM-Ep_Z9lp8TNDCi2lB5IQFbKVpBFaAItDDyVUvKNPfBovmKlnPRFLZYjLbgocnU3tcy0YB8RZegC56Gxn7g_WkphptCVPm7IDeCE9l5gcFafuY0">Fletcher‚ÄìReeves method</a></li>
</ul></li>
</ul>
</section>
<section id="non-symmetric-systems-and-the-generalized-minimal-residual-method-gmres-y.-saad-m.-schultz-1986" class="level2">
<h2 class="anchored" data-anchor-id="non-symmetric-systems-and-the-generalized-minimal-residual-method-gmres-y.-saad-m.-schultz-1986">Non-symmetric systems and the generalized minimal residual method (GMRES) <a href="https://epubs.siam.org/doi/10.1137/0907058">(Y. Saad, M. Schultz, 1986)</a></h2>
<p>Before we discussed symmetric positive definite systems. What happens if <span class="math inline">A</span> is non-symmetric?</p>
<p>We can still orthogonalize the Krylov subspace using Arnoldi process, and get</p>
<p><span class="math display">A Q_j = Q_j H_j + h_{j,j-1}q_j e^{\top}_{j-1}.</span></p>
<p>Let us rewrite the latter expression as</p>
<p><span class="math display"> A Q_j = Q_j H_j + h_{j,j-1}q_j e^{\top}_{j-1} = Q_{j+1} \widetilde H_j, \quad \widetilde H_j =
\begin{bmatrix} h_{0,0} &amp; h_{0,1} &amp; \dots &amp; h_{0,j-2} &amp; h_{0,j-1} \\ h_{1,0} &amp; h_{1,1} &amp; \dots &amp; h_{1,j-2} &amp; h_{1,j-1} \\ 0&amp; h_{2,2} &amp;  \dots &amp; h_{2,j-2} &amp; h_{2,j-1} \\
0&amp; 0 &amp; \ddots &amp; \vdots &amp; \vdots  \\
0&amp; 0 &amp;  &amp; h_{j,j-1} &amp; h_{j-1,j-1} \\ 0&amp; 0 &amp; \dots &amp; 0 &amp; h_{j,j-1}\end{bmatrix}</span></p>
<p>Then, if we need to minimize the residual over the Krylov subspace, we have</p>
<p><span class="math display">x_j = x_0 + Q_j c_j </span></p>
<p>and <span class="math inline">x_j</span> has to be selected as</p>
<p><span class="math display"> \Vert A x_j - f \Vert_2 =  \Vert A Q_j c_j - r_0 \Vert_2 \rightarrow \min_{c_j}.</span></p>
<p>Using the Arnoldi recursion, we have</p>
<p><span class="math display"> \Vert Q_{j+1} \widetilde H_j c_j -  r_0 \Vert_2 \rightarrow \min_{c_j}.</span></p>
<p>Using the orthogonal invariance under multiplication by unitary matrix, we get</p>
<p><span class="math display"> \Vert \widetilde H_j c_j - \gamma e_0 \Vert_2 \rightarrow \min_{c_j},</span></p>
<p>where we have used that <span class="math inline">Q^*_{j+1} r_0 = \gamma e_0, \gamma = \Vert r_0 \Vert</span></p>
<ul>
<li><p>This is just a linear least squares with <span class="math inline">(j+1)</span> equations and <span class="math inline">j</span> unknowns.</p></li>
<li><p>The matrix is also upper Hessenberg, thus its QR factorization can be computed in a very cheap way.</p></li>
<li><p>This allows the computation of <span class="math inline">c_j</span>. This method is called <strong>GMRES</strong> (generalized minimal residual)</p></li>
</ul>
</section>
<section id="summary-of-the-gmres" class="level2">
<h2 class="anchored" data-anchor-id="summary-of-the-gmres">Summary of the GMRES</h2>
<ul>
<li>Minimizes the residual directly</li>
<li>No normal equations</li>
<li>Memory grows with the number of iterations as <span class="math inline">\mathcal{O}(nj)</span>, so <strong>restarts</strong> typically implemented (just start GMRES from the new initial guess).</li>
</ul>
<div id="cell-38" class="cell" data-slideshow="{&quot;slide_type&quot;:&quot;slide&quot;}" data-execution_count="7">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> scipy.sparse.linalg <span class="im">as</span> la</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.sparse <span class="im">import</span> csc_matrix, csr_matrix</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> time</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>matplotlib inline</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>n <span class="op">=</span> <span class="dv">150</span></span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>ex <span class="op">=</span> np.ones(n)<span class="op">;</span></span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>lp1 <span class="op">=</span> sp.sparse.spdiags(np.vstack((ex,  <span class="op">-</span><span class="dv">2</span><span class="op">*</span>ex, ex)), [<span class="op">-</span><span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>], n, n, <span class="st">'csr'</span>)<span class="op">;</span> </span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>e <span class="op">=</span> sp.sparse.eye(n)</span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>A <span class="op">=</span> sp.sparse.kron(lp1, e) <span class="op">+</span> sp.sparse.kron(e, lp1)</span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>A <span class="op">=</span> csr_matrix(A)</span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a>rhs <span class="op">=</span> np.ones(n <span class="op">*</span> n)</span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">5</span>))</span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a>f, (ax1, ax2) <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">5</span>))</span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> restart <span class="kw">in</span> [<span class="dv">5</span>, <span class="dv">40</span>, <span class="dv">200</span>]:</span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a>    hist <span class="op">=</span> []</span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> callback(rk):</span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true" tabindex="-1"></a>        hist.append(np.linalg.norm(rk) <span class="op">/</span> np.linalg.norm(rhs))</span>
<span id="cb7-22"><a href="#cb7-22" aria-hidden="true" tabindex="-1"></a>    st <span class="op">=</span> time.time()</span>
<span id="cb7-23"><a href="#cb7-23" aria-hidden="true" tabindex="-1"></a>    sol <span class="op">=</span> la.gmres(A, rhs, x0<span class="op">=</span>np.zeros(n<span class="op">*</span>n), maxiter<span class="op">=</span><span class="dv">200</span>, restart<span class="op">=</span>restart, callback<span class="op">=</span>callback, tol<span class="op">=</span><span class="fl">1e-16</span>)</span>
<span id="cb7-24"><a href="#cb7-24" aria-hidden="true" tabindex="-1"></a>    current_time <span class="op">=</span> time.time() <span class="op">-</span> st</span>
<span id="cb7-25"><a href="#cb7-25" aria-hidden="true" tabindex="-1"></a>    ax1.semilogy(np.array(hist), label<span class="op">=</span><span class="st">'rst=</span><span class="sc">{}</span><span class="st">'</span>.<span class="bu">format</span>(restart))</span>
<span id="cb7-26"><a href="#cb7-26" aria-hidden="true" tabindex="-1"></a>    ax2.semilogy([current_time <span class="op">*</span> i <span class="op">/</span> <span class="bu">len</span>(hist) <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(hist))], np.array(hist), label<span class="op">=</span><span class="st">'rst=</span><span class="sc">{}</span><span class="st">'</span>.<span class="bu">format</span>(restart))</span>
<span id="cb7-27"><a href="#cb7-27" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb7-28"><a href="#cb7-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-29"><a href="#cb7-29" aria-hidden="true" tabindex="-1"></a>ax1.legend(loc<span class="op">=</span><span class="st">'best'</span>)</span>
<span id="cb7-30"><a href="#cb7-30" aria-hidden="true" tabindex="-1"></a>ax2.legend(loc<span class="op">=</span><span class="st">'best'</span>)</span>
<span id="cb7-31"><a href="#cb7-31" aria-hidden="true" tabindex="-1"></a>ax1.set_xlabel(<span class="st">"Number of outer iterations"</span>, fontsize<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb7-32"><a href="#cb7-32" aria-hidden="true" tabindex="-1"></a>ax2.set_xlabel(<span class="st">"Time, sec"</span>, fontsize<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb7-33"><a href="#cb7-33" aria-hidden="true" tabindex="-1"></a>ax1.set_ylabel(<span class="vs">r"$\frac{||r_k||_2}{||rhs||_2}$"</span>, fontsize<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb7-34"><a href="#cb7-34" aria-hidden="true" tabindex="-1"></a>ax2.set_ylabel(<span class="vs">r"$\frac{||r_k||_2}{||rhs||_2}$"</span>, fontsize<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb7-35"><a href="#cb7-35" aria-hidden="true" tabindex="-1"></a>plt.sca(ax1)</span>
<span id="cb7-36"><a href="#cb7-36" aria-hidden="true" tabindex="-1"></a>plt.yticks(fontsize<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb7-37"><a href="#cb7-37" aria-hidden="true" tabindex="-1"></a>plt.sca(ax2)</span>
<span id="cb7-38"><a href="#cb7-38" aria-hidden="true" tabindex="-1"></a>plt.yticks(fontsize<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb7-39"><a href="#cb7-39" aria-hidden="true" tabindex="-1"></a>f.tight_layout()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>&lt;Figure size 1000x500 with 0 Axes&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="lecture-13_files/figure-html/cell-5-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="cell-39" class="cell" data-slideshow="{&quot;slide_type&quot;:&quot;slide&quot;}" data-execution_count="8">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> scipy.sparse.linalg <span class="im">as</span> la</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>matplotlib inline</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Example from http://www.caam.rice.edu/~embree/39961.pdf</span></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>A <span class="op">=</span> np.array([[<span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>],</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>              [<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">3</span>],</span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>              [<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">1</span>]]</span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a>rhs <span class="op">=</span> np.array([<span class="dv">2</span>, <span class="op">-</span><span class="dv">4</span>, <span class="dv">1</span>])</span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a>x0 <span class="op">=</span> np.zeros(<span class="dv">3</span>)</span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> restart <span class="kw">in</span> [<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>]:</span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a>    hist <span class="op">=</span> []</span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> callback(rk):</span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a>        hist.append(np.linalg.norm(rk)<span class="op">/</span>np.linalg.norm(rhs))</span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a>    _ <span class="op">=</span> la.gmres(A, rhs, x0<span class="op">=</span>x0, maxiter<span class="op">=</span><span class="dv">20</span>, restart<span class="op">=</span>restart, callback<span class="op">=</span>callback)</span>
<span id="cb9-20"><a href="#cb9-20" aria-hidden="true" tabindex="-1"></a>    plt.semilogy(np.array(hist), label<span class="op">=</span><span class="st">'rst=</span><span class="sc">{}</span><span class="st">'</span>.<span class="bu">format</span>(restart))</span>
<span id="cb9-21"><a href="#cb9-21" aria-hidden="true" tabindex="-1"></a>plt.legend(fontsize<span class="op">=</span><span class="dv">22</span>)</span>
<span id="cb9-22"><a href="#cb9-22" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Number of outer iterations"</span>, fontsize<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb9-23"><a href="#cb9-23" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="vs">r"$\frac{||r_k||_2}{||rhs||_2}$"</span>, fontsize<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb9-24"><a href="#cb9-24" aria-hidden="true" tabindex="-1"></a>plt.xticks(fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb9-25"><a href="#cb9-25" aria-hidden="true" tabindex="-1"></a>plt.yticks(fontsize<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb9-26"><a href="#cb9-26" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="lecture-13_files/figure-html/cell-6-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="next-lecture" class="level2">
<h2 class="anchored" data-anchor-id="next-lecture">Next lecture</h2>
<ul>
<li>Iterative methods continued (BiCG, MINRES)</li>
<li>Preconditioners</li>
</ul>
</section>
<section id="questions" class="level1">
<h1>Questions?</h1>
<div id="cell-42" class="cell" data-slideshow="{&quot;slide_type&quot;:&quot;skip&quot;}" data-execution_count="1">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> IPython.core.display <span class="im">import</span> HTML</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> css_styling():</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>    styles <span class="op">=</span> <span class="bu">open</span>(<span class="st">"./styles/custom.css"</span>, <span class="st">"r"</span>).read()</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> HTML(styles)</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>css_styling()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="1">
<link href="http://fonts.googleapis.com/css?family=Fenix" rel="stylesheet" type="text/css">
<link href="http://fonts.googleapis.com/css?family=Alegreya+Sans:100,300,400,500,700,800,900,100italic,300italic,400italic,500italic,700italic,800italic,900italic" rel="stylesheet" type="text/css">
<link href="http://fonts.googleapis.com/css?family=Source+Code+Pro:300,400" rel="stylesheet" type="text/css">
<style>
    @font-face {
        font-family: "Computer Modern";
        src: url('http://mirrors.ctan.org/fonts/cm-unicode/fonts/otf/cmunss.otf');
    }
    div.cell{
        /*width:80%;*/
        /*margin-left:auto !important;
        margin-right:auto;*/
    }
    h1 {
        font-family: 'Alegreya Sans', sans-serif;
    }
    h2 {
        font-family: 'Fenix', serif;
    }
    h3{
        font-family: 'Fenix', serif;
        margin-top:12px;
        margin-bottom: 3px;
       }
    h4{
        font-family: 'Fenix', serif;
       }
    h5 {
        font-family: 'Alegreya Sans', sans-serif;
    }      
    div.text_cell_render{
        font-family: 'Alegreya Sans',Computer Modern, "Helvetica Neue", Arial, Helvetica, Geneva, sans-serif;
        line-height: 1.2;
        font-size: 120%;
        /*width:70%;*/
        /*margin-left:auto;*/
        margin-right:auto;
    }
    .CodeMirror{
            font-family: "Source Code Pro";
            font-size: 90%;
    }
/*    .prompt{
        display: None;
    }*/
    .text_cell_render h1 {
        font-weight: 200;
        font-size: 50pt;
        line-height: 110%;
        color:#CD2305;
        margin-bottom: 0.5em;
        margin-top: 0.5em;
        display: block;
    }   
    .text_cell_render h5 {
        font-weight: 300;
        font-size: 16pt;
        color: #CD2305;
        font-style: italic;
        margin-bottom: .5em;
        margin-top: 0.5em;
        display: block;
    }
    
    li {
        line-height: 110%;
    }
    .warning{
        color: rgb( 240, 20, 20 )
        }  

</style>

<script>
    MathJax.Hub.Config({
                        TeX: {
                           extensions: ["AMSmath.js"]
                           },
                tex2jax: {
                    inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                    displayMath: [ ['$$','$$'], ["\\[","\\]"] ]
                },
                displayAlign: 'center', // Change this to 'center' to center equations.
                "HTML-CSS": {
                    styles: {'.MathJax_Display': {"margin": 4}}
                }
        });
</script>
</div>
</div>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "Óßã";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/nla360\.fmin\.xyz");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
          // target, if specified
          link.setAttribute("target", "_blank");
          if (link.getAttribute("rel") === null) {
            link.setAttribute("rel", "noopener");
          }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




<footer class="footer"><div class="nav-footer"><div class="nav-footer-center"><div class="toc-actions"><ul><li><a href="https://github.dev/MerkulovDaniil/nla360/blob/main/lectures/lecture-13/lecture-13.ipynb" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li></ul></div></div></div></footer></body></html>