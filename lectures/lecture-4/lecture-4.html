<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.40">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Lecture 4: Matrix rank, low-rank approximation, SVD</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../favicon.svg" rel="icon" type="image/svg+xml">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-549806ee2085284f45b00abea8c6df48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-7f2a93ce03cd03d77aaf1c7855d4b88b.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>
<script src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/copy-tex.min.js" integrity="sha384-ww/583aHhxWkz5DEVn6OKtNiIaLi2iBRNZXfJRiY1Ai7tnJ9UXpEsyvOITVpTl4A" crossorigin="anonymous"></script>

  <script>window.backupDefine = window.define; window.define = undefined;</script><script src="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css">

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<meta property="og:title" content="Lecture 4: Matrix rank, low-rank approximation, SVD">
<meta property="og:description" content="">
<meta property="og:image" content="https://nla360.fmin.xyz/lectures/lecture-4/skeleton.png">
<meta property="og:image:height" content="387">
<meta property="og:image:width" content="1011">
<meta name="twitter:title" content="Lecture 4: Matrix rank, low-rank approximation, SVD">
<meta name="twitter:description" content="">
<meta name="twitter:image" content="https://nla360.fmin.xyz/lectures/lecture-4/skeleton.png">
<meta name="twitter:image-height" content="387">
<meta name="twitter:image-width" content="1011">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../../logo.svg" alt="nla360.fmin.xyz" class="navbar-logo">
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../program.html"> 
<span class="menu-text">üöÄ –ú–∞—Ç–µ—Ä–∏–∞–ª—ã</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../projects.html"> 
<span class="menu-text">üìΩÔ∏è –ü—Ä–æ–µ–∫—Ç—ã</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools tools-wide">
    <a href="https://github.com/MerkulovDaniil/nla360" title="" class="quarto-navigation-tool px-1" aria-label=""><i class="bi bi-github"></i></a>
    <a href="https://www.youtube.com/@fmin" title="" class="quarto-navigation-tool px-1" aria-label=""><i class="bi bi-youtube"></i></a>
    <a href="https://t.me/nla360" title="" class="quarto-navigation-tool px-1" aria-label=""><i class="bi bi-telegram"></i></a>
    <a href="" title="" class="quarto-navigation-tool px-1" aria-label=""><i class="bi bi-table"></i></a>
    <a href="https://fmin.xyz" title="" class="quarto-navigation-tool px-1" aria-label=""><i class="bi bi-gem"></i></a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block"></header>

<header id="title-block-header">
</header>


<section id="previous-lecture" class="level2">
<h2 class="anchored" data-anchor-id="previous-lecture">Previous lecture</h2>
<ul>
<li>Peak performance of algorithm</li>
<li>Complexity of matrix multiplication algorithms</li>
<li>Idea of blocking (why it is good?)</li>
</ul>
</section>
<section id="todays-lecture" class="level2">
<h2 class="anchored" data-anchor-id="todays-lecture">Todays lecture</h2>
<ul>
<li>Matrix rank</li>
<li>Skeleton decomposition</li>
<li>Low-rank approximation</li>
<li>Singular Value Decomposition (SVD)</li>
<li>Applications of SVD</li>
</ul>
</section>
<section id="matrix-and-linear-spaces" class="level2">
<h2 class="anchored" data-anchor-id="matrix-and-linear-spaces">Matrix and linear spaces</h2>
<ul>
<li>A matrix can be considered as a sequence of vectors that are columns of a matrix:</li>
</ul>
<p><span class="math display"> A = [a_1, \ldots, a_m], </span></p>
<p>where <span class="math inline">a_m \in \mathbb{C}^{n\times 1}</span>.</p>
<ul>
<li>A matrix-by-vector product is equivalent to taking a linear combination of those columns</li>
</ul>
<p><span class="math display"> y =  Ax \quad \Longleftrightarrow \quad y = a_1 x_1 + a_2 x_2 + \ldots +a_m x_m. </span></p>
<ul>
<li>This is a special case of <strong>block matrix notation</strong> (columns are also blocks) that we have already seen (blocking to fit cache memory, Strassen algorithm).</li>
</ul>
</section>
<section id="linear-dependence" class="level2">
<h2 class="anchored" data-anchor-id="linear-dependence">Linear dependence</h2>
<p><strong>Definition.</strong> Vectors <span class="math inline">a_i</span> are called <strong>linearly dependent</strong>, if there exist simultaneously non-zero coefficients <span class="math inline">x_i</span> such that</p>
<p><span class="math display">\sum_i a_i x_i = 0,</span></p>
<p>or in the matrix form</p>
<p><span class="math display"> Ax = 0, \quad \Vert x \Vert \ne 0. </span></p>
<p>In this case, we say that the matrix <span class="math inline">A</span> has a non-trivial <strong>nullspace</strong> (or <strong>kernel</strong>) denoted by <span class="math inline">N(A)</span> (or <span class="math inline">\text{ker}(A)</span>).</p>
<p>Vectors that are not linearly dependent are called <strong>linearly independent</strong>.</p>
</section>
<section id="linear-vector-space" class="level2">
<h2 class="anchored" data-anchor-id="linear-vector-space">Linear (vector) space</h2>
<p>A <strong>linear space</strong> spanned by vectors <span class="math inline">\{a_1, \ldots, a_m\}</span> is defined as all possible vectors of the form</p>
<p><span class="math display"> \mathcal{L}(a_1, \ldots, a_m) = \left\{y: y = \sum_{i=1}^m a_i x_i, \, \forall x_i, \, i=1,\dots, n \right\}, </span></p>
<p>In the matrix form, the linear space is a set of all <span class="math inline">y</span> such that</p>
<p><span class="math display">y = A x.</span></p>
<p>This set is also called the <strong>range</strong> (or <strong>image</strong>) of the matrix, denoted by <span class="math inline">\text{range}(A)</span> (or <span class="math inline">\text{im}(A)</span>) respectively.</p>
</section>
<section id="dimension-of-a-linear-space" class="level2">
<h2 class="anchored" data-anchor-id="dimension-of-a-linear-space">Dimension of a linear space</h2>
<ul>
<li><p>The dimension of a linear space <span class="math inline">\text{im}(A)</span> denoted by <span class="math inline">\text{dim}\, \text{im} (A)</span> is the minimal number of vectors required to represent each vector from <span class="math inline">\text{im} (A)</span>.</p></li>
<li><p>The dimension of <span class="math inline">\text{im}(A)</span> has a direct connection to the <strong>matrix rank</strong>.</p></li>
</ul>
</section>
<section id="matrix-rank" class="level2">
<h2 class="anchored" data-anchor-id="matrix-rank">Matrix rank</h2>
<ul>
<li><p>Rank of a matrix <span class="math inline">A</span> is a maximal number of linearly independent <em>columns</em> in a matrix <span class="math inline">A</span>, or the <strong>dimension of its column space</strong> <span class="math inline">= \text{dim} \, \text{im}(A)</span>.</p></li>
<li><p>You can also use linear combination of <em>rows</em> to define the rank, i.e.&nbsp;formally there are two ranks: column rank and row rank of a matrix.</p></li>
</ul>
<p><strong>Theorem</strong><br>
The dimension of the column space of the matrix is equal to the dimension of its row space.</p>
<p><a href="https://ocw.mit.edu/courses/mathematics/18-701-algebra-i-fall-2010/study-materials/MIT18_701F10_rrk_crk.pdf">Proof</a></p>
<ul>
<li><p>In the matrix form this fact can be written as <span class="math inline">\mathrm{dim}\ \mathrm{im} (A) = \mathrm{dim}\ \mathrm{im} (A^\top)</span>.</p></li>
<li><p>Thus, there is a single rank!</p></li>
</ul>
</section>
<section id="full-rank-matrix" class="level2">
<h2 class="anchored" data-anchor-id="full-rank-matrix">Full-rank matrix</h2>
<ul>
<li>A matrix <span class="math inline">A \in \mathbb{R}^{m \times n}</span> is called of <strong>full-rank</strong>, if <span class="math inline">\mathrm{rank}(A) = \min(m, n)</span>.</li>
</ul>
<p>Suppose, we have a linear space, spanned by <span class="math inline">n</span> vectors. Let these vectors be random with elements from standard normal distribution <span class="math inline">\mathcal{N}(0, 1)</span>.</p>
<p><strong>Q</strong>: What is the probability of the fact that this subspace has dimension <span class="math inline">m &lt; n</span>?</p>
<p><strong>A</strong>: Random matrix has full rank with probability 1.</p>
</section>
<section id="dimensionality-reduction" class="level2">
<h2 class="anchored" data-anchor-id="dimensionality-reduction">Dimensionality reduction</h2>
<ul>
<li>A lot of data from real-world applications are high dimensional, for instance images (e.g.&nbsp;<span class="math inline">512\times 512</span> pixels), texts, graphs.</li>
<li>However, working with high-dimensional data is not an easy task.</li>
<li>Is it possible to reduce the dimensionality, preserving important relations between objects such as distance?</li>
</ul>
<p><strong><a href="http://cseweb.ucsd.edu/~dasgupta/papers/jl.pdf">Johnson‚ÄìLindenstrauss lemma</a></strong></p>
<p>Let <span class="math inline">N\gg 1</span>. Given <span class="math inline">0 &lt; \epsilon &lt; 1</span>, a set of <span class="math inline">m</span> points in <span class="math inline">\mathbb{R}^N</span> and <span class="math inline">n &gt; \frac{8 \log m}{\epsilon^2}</span> (we want <span class="math inline">n\ll N</span>).</p>
<p>Then there exists linear map <span class="math inline">f</span> from <span class="math inline">\mathbb{R}^N \rightarrow \mathbb{R}^n</span> such that the following inequality holds:</p>
<p><span class="math display">(1 - \epsilon) \Vert u - v \Vert^2 \leq \Vert f(u) - f(v) \Vert^2 \leq (1 + \epsilon) \Vert u - v \Vert^2.</span></p>
<ul>
<li>This theorem states that there exists a map from high- to a low-dimensional space so that distances between points in these spaces are almost the same.</li>
<li>It is not very practical due to the dependence on <span class="math inline">\epsilon</span>.</li>
<li>This lemma does not give a recipe how to construct <span class="math inline">f</span>, but guarantees that <span class="math inline">f</span> exists.</li>
</ul>
</section>
<section id="skeleton-decomposition" class="level2">
<h2 class="anchored" data-anchor-id="skeleton-decomposition">Skeleton decomposition</h2>
<p>A very useful representation for computation of the matrix rank is the <strong>skeleton decomposition</strong> and is closely related to the rank. This decompositions explains, why and how matrices of low rank can be compressed.</p>
<p>It can be graphically represented as follows:<br>
<img src="./skeleton.png" width="90%"> or in the matrix form</p>
<p><span class="math display"> A = C \widehat{A}^{-1} R, </span></p>
<p>where <span class="math inline">C</span> are some <span class="math inline">k=\mathrm{rank}(A)</span> columns of <span class="math inline">A</span>, <span class="math inline">R</span> are some <span class="math inline">k</span> rows of <span class="math inline">A</span> and <span class="math inline">\widehat{A}</span> is the <strong>nonsingular</strong> submatrix on the intersection.</p>
<section id="remark" class="level3">
<h3 class="anchored" data-anchor-id="remark">Remark</h3>
<p>We have not yet formally defined the inverse, so just a reminder:</p>
<ul>
<li>An inverse of the matrix <span class="math inline">P</span> is the matrix <span class="math inline">Q = P^{-1}</span> such that $ P Q = QP = I$.<br>
</li>
<li>If the matrix is square and has full rank then the inverse exists.</li>
</ul>
</section>
<section id="proof-for-the-skeleton-decomposition" class="level3">
<h3 class="anchored" data-anchor-id="proof-for-the-skeleton-decomposition">Proof for the skeleton decomposition</h3>
<ul>
<li><p>Let <span class="math inline">C\in \mathbb{C}^{n\times k}</span> be the <span class="math inline">k</span> columns based on the nonsingular submatrix <span class="math inline">\widehat{A}</span>. Therefore they are linearly independent.</p></li>
<li><p>Take any other column <span class="math inline">a_i</span> of <span class="math inline">A</span>. Then <span class="math inline">a_i</span> can be represented as a linear combination of the columns of <span class="math inline">C</span>, i.e.&nbsp;<span class="math inline">a_i = C x_i</span>, where <span class="math inline">x_i</span> is a vector of coefficients.</p></li>
<li><p><span class="math inline">a_i = C x_i</span> are <span class="math inline">n</span> equations. We take <span class="math inline">k</span> equations of those corresponding to the rows that contain <span class="math inline">\widehat{A}</span> and get the equation</p></li>
</ul>
<p><span class="math display">\widehat{r}_i = \widehat{A} x_i \quad \Longrightarrow \quad x_i = \widehat{A}^{-1} \widehat r_i</span></p>
<p>Thus, <span class="math inline">a_i = C\widehat{A}^{-1} \widehat r_i</span> for every <span class="math inline">i</span> and</p>
<p><span class="math display">A = [a_1,\dots, a_m] = C\widehat{A}^{-1} R.</span></p>
</section>
<section id="a-closer-look-on-the-skeleton-decomposition" class="level3">
<h3 class="anchored" data-anchor-id="a-closer-look-on-the-skeleton-decomposition">A closer look on the skeleton decomposition</h3>
<ul>
<li>Any rank-<span class="math inline">r</span> matrix can be written in the form</li>
</ul>
<p><span class="math display">A = C \widehat{A}^{-1} R,</span></p>
<p>where <span class="math inline">C</span> is <span class="math inline">n \times r</span>, <span class="math inline">R</span> is <span class="math inline">r \times m</span> and <span class="math inline">\widehat{A}</span> is <span class="math inline">r \times r</span>, or</p>
<p><span class="math display"> A = UV, </span></p>
<p>where <span class="math inline">U</span> and <span class="math inline">V</span> are not unique, e.g.&nbsp;<span class="math inline">U = C \widehat{A}^{-1}</span>, <span class="math inline">V=R</span>.</p>
<ul>
<li><p>The form <span class="math inline">A = U V</span> is standard for skeleton decomposition.</p></li>
<li><p>Thus, every rank-<span class="math inline">r</span> matrix can be written as a product of a ‚Äúskinny‚Äù (‚Äútall‚Äù) matrix <span class="math inline">U</span> by a ‚Äúfat‚Äù (‚Äúshort‚Äù) matrix <span class="math inline">V</span>.</p></li>
</ul>
<p>In the index form, it is</p>
<p><span class="math display"> a_{ij} = \sum_{\alpha=1}^r u_{i \alpha} v_{\alpha j}. </span></p>
<p>For rank 1, we have</p>
<p><span class="math display"> a_{ij} = u_i v_j, </span></p>
<p>i.e.&nbsp;it is a separation of indices and rank-<span class="math inline">r</span> is a sum of rank-<span class="math inline">1</span> matrices!</p>
</section>
<section id="storage" class="level3">
<h3 class="anchored" data-anchor-id="storage">Storage</h3>
<p>It is interesting to note, that for the rank-<span class="math inline">r</span> matrix</p>
<p><span class="math display">A = U V</span></p>
<p>only <span class="math inline">U</span> and <span class="math inline">V</span> can be stored, which gives us <span class="math inline">(n+m) r</span> parameters, so it can be used for compression. We can also compute matrix-by-vector <span class="math inline">Ax</span> product much faster:</p>
<ul>
<li>Multiplication <span class="math inline">y = Vx</span> costs <span class="math inline">\mathcal{O}(mr)</span> flops.</li>
<li>Multiplication <span class="math inline">z = Uy</span> costs <span class="math inline">\mathcal{O}(nr)</span> flops.</li>
</ul>
<p>The same works for addition, elementwise multiplication, etc. For addition:</p>
<p><span class="math display">    A_1 + A_2 = U_1 V_1 + U_2 V_2 = [U_1|U_2] [V_1^\top|V_2^\top]^\top </span></p>
<div id="cell-20" class="cell" data-slideshow="{&quot;slide_type&quot;:&quot;slide&quot;}" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co">#A fast matrix-by-vector product demo</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> jax</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> jax.numpy <span class="im">as</span> jnp</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>n <span class="op">=</span> <span class="dv">4096</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>r <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>u <span class="op">=</span> jax.random.normal(jax.random.PRNGKey(<span class="dv">0</span>), (n, r))</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>v <span class="op">=</span> jax.random.normal(jax.random.PRNGKey(<span class="dv">10</span>), (n, r))</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> u <span class="op">@</span> v.T</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> jax.random.normal(jax.random.PRNGKey(<span class="dv">1</span>), (n,))</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(n<span class="op">*</span>n<span class="op">/</span>(<span class="dv">2</span><span class="op">*</span>n<span class="op">*</span>r))</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>timeit (a <span class="op">@</span> x).block_until_ready()</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>timeit (u <span class="op">@</span> (v.T <span class="op">@</span> x)).block_until_ready()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Platform 'METAL' is experimental and not all JAX functionality may be correctly supported!
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
W0000 00:00:1730792144.773664 9725347 mps_client.cc:510] WARNING: JAX Apple GPU support is experimental and not all JAX functionality is correctly supported!
I0000 00:00:1730792144.809984 9725347 service.cc:145] XLA service 0x10c42af30 initialized for platform METAL (this does not guarantee that XLA will be used). Devices:
I0000 00:00:1730792144.810137 9725347 service.cc:153]   StreamExecutor device (0): Metal, &lt;undefined&gt;
I0000 00:00:1730792144.813529 9725347 mps_client.cc:406] Using Simple allocator.
I0000 00:00:1730792144.813538 9725347 mps_client.cc:384] XLA backend will use up to 11452858368 bytes on device 0 for SimpleAllocator.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Metal device set to: Apple M2 Pro

systemMemory: 16.00 GB
maxCacheSize: 5.33 GB

204.8
612 Œºs ¬± 4.04 Œºs per loop (mean ¬± std. dev. of 7 runs, 1,000 loops each)
400 Œºs ¬± 32.9 Œºs per loop (mean ¬± std. dev. of 7 runs, 1,000 loops each)</code></pre>
</div>
</div>
</section>
</section>
<section id="computing-matrix-rank" class="level2">
<h2 class="anchored" data-anchor-id="computing-matrix-rank">Computing matrix rank</h2>
<p>We can also try to compute the matrix rank using the built-in <code>jnp.linalg.matrix_rank</code> function</p>
<div id="cell-22" class="cell" data-slideshow="{&quot;slide_type&quot;:&quot;slide&quot;}" data-execution_count="15">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Computing matrix rank</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>n <span class="op">=</span> <span class="dv">50</span> </span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> np.ones((n, n))</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Rank of the matrix:'</span>, np.linalg.matrix_rank(a))</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> a <span class="op">+</span> <span class="fl">1e-8</span> <span class="op">*</span> np.random.randn(<span class="op">*</span>a.shape)</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Rank of the matrix:'</span>, np.linalg.matrix_rank(b, tol<span class="op">=</span><span class="fl">1e-7</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Rank of the matrix: 1
Rank of the matrix: 10</code></pre>
</div>
</div>
<p><font color="red"> So, small perturbations might crucially affect the rank! </font></p>
<section id="instability-of-the-matrix-rank" class="level3">
<h3 class="anchored" data-anchor-id="instability-of-the-matrix-rank">Instability of the matrix rank</h3>
<p>For any rank-<span class="math inline">r</span> matrix <span class="math inline">A</span> with <span class="math inline">r &lt; \min(m, n)</span> there is a matrix <span class="math inline">B</span> such that its rank is equal to <span class="math inline">\min(m, n)</span> and</p>
<p><span class="math display"> \Vert A - B \Vert = \epsilon. </span></p>
<p><strong>Q</strong>: So, does this mean that numerically matrix rank has no meaning? (I.e., small perturbations lead to full rank!)</p>
<p><strong>A</strong>: No.&nbsp;We should find a matrix <span class="math inline">B</span> such that <span class="math inline">\|A-B\| = \epsilon</span> and <span class="math inline">B</span> has minimal rank. So we can only compute rank with given accuracy <span class="math inline">\epsilon</span>. One of the approaches to compute matrix rank <span class="math inline">r</span> is SVD.</p>
</section>
</section>
<section id="low-rank-approximation" class="level2">
<h2 class="anchored" data-anchor-id="low-rank-approximation">Low rank approximation</h2>
<p>The important problem in many applications is to find low-rank approximation of the given matrix with given accurcacy <span class="math inline">\epsilon</span> or rank <span class="math inline">r</span>. <br> Examples: * principal component analysis * recommender systems * least squares * neural network compression</p>
<p>These problems can be solved by SVD.</p>
</section>
<section id="singular-value-decomposition" class="level2">
<h2 class="anchored" data-anchor-id="singular-value-decomposition">Singular value decomposition</h2>
<p>To compute low-rank approximation, we need to compute <strong>singular value decomposition</strong> (SVD).</p>
<p><strong>Theorem</strong> Any matrix <span class="math inline">A\in \mathbb{C}^{n\times m}</span> can be written as a product of three matrices:</p>
<p><span class="math display"> A = U \Sigma V^*, </span></p>
<p>where - <span class="math inline">U</span> is an <span class="math inline">n \times K</span> unitary matrix, - <span class="math inline">V</span> is an <span class="math inline">m \times K</span> unitary matrix, <span class="math inline">K = \min(m, n)</span>, - <span class="math inline">\Sigma</span> is a diagonal matrix with non-negative elements <span class="math inline">\sigma_1 \geq  \ldots, \geq \sigma_K</span> on the diagonal. - Moreover, if <span class="math inline">\text{rank}(A) = r</span>, then <span class="math inline">\sigma_{r+1} = \dots = \sigma_K = 0</span>.</p>
<section id="proof" class="level3">
<h3 class="anchored" data-anchor-id="proof">Proof</h3>
<ul>
<li>Matrix <span class="math inline">A^*A</span> is Hermitian, hence diagonalizable in unitary basis (will be discussed further in the course).</li>
<li><span class="math inline">A^*A\geq0</span> (non-negative definite), so eigenvalues are non-negative. Therefore, there exists unitary matrix <span class="math inline">V = [v_1, \dots, v_n]</span> such that</li>
</ul>
<p><span class="math display"> V^* A^* A V = \text{diag}(\sigma_1^2,\dots, \sigma_n^2), \quad \sigma_1\geq \sigma_2\geq \dots \geq \sigma_n. </span></p>
<p>Let <span class="math inline">\sigma_i = 0</span> for <span class="math inline">i&gt;r</span>, where <span class="math inline">r</span> is some integer. <br> Let <span class="math inline">V_r= [v_1, \dots, v_r]</span>, <span class="math inline">\Sigma_r = \text{diag}(\sigma_1, \dots,\sigma_r)</span>. Hence</p>
<p><span class="math display"> V^*_r A^* A V_r = \Sigma_r^2 \quad \Longrightarrow \quad (\Sigma_r^{-1} V_r^* A^*) (A V_r\Sigma_r^{-1} ) = I. </span></p>
<p>As a result, matrix <span class="math inline">U_r = A V_r\Sigma_r^{-1}</span> satisfies <span class="math inline">U_r^* U_r = I</span> and hence has orthogonal columns. <br> Let us add to <span class="math inline">U_r</span> any orthogonal columns that are orthogonal to columns in <span class="math inline">U_r</span> and denote this matrix as <span class="math inline">U</span>. Then</p>
<p><span class="math display"> AV = U \begin{bmatrix} \Sigma_r &amp; 0 \\ 0 &amp; 0 \end{bmatrix}\quad \Longrightarrow \quad U^* A V = \begin{bmatrix}\Sigma_r &amp; 0 \\ 0 &amp; 0 \end{bmatrix}.
</span></p>
<p>Since multiplication by non-singular matrices does not change rank of <span class="math inline">A</span>, we have <span class="math inline">r = \text{rank}(A)</span>.</p>
<p><strong>Corollary 1</strong>: <span class="math inline">A = \displaystyle{\sum_{\alpha=1}^r} \sigma_\alpha u_\alpha v_\alpha^*</span> or elementwise <span class="math inline">a_{ij} = \displaystyle{\sum_{\alpha=1}^r} \sigma_\alpha u_{i\alpha} \overline{v}_{j\alpha}</span></p>
<p><strong>Corollary 2</strong>: <span class="math display">\text{ker}(A) = \mathcal{L}\{v_{r+1},\dots,v_n\}</span></p>
<p><span class="math display">\text{im}(A) = \mathcal{L}\{u_{1},\dots,u_r\}</span></p>
<p><span class="math display">\text{ker}(A^*) = \mathcal{L}\{u_{r+1},\dots,u_n\}</span></p>
<p><span class="math display">\text{im}(A^*) = \mathcal{L}\{v_{1},\dots,v_r\}</span></p>
</section>
</section>
<section id="eckart-young-theorem" class="level1">
<h1>Eckart-Young theorem</h1>
<p>The best low-rank approximation can be computed by SVD.</p>
<p><strong>Theorem:</strong> Let <span class="math inline">r &lt; \text{rank}(A)</span>, <span class="math inline">A_r = U_r \Sigma_r V_r^*</span>. Then</p>
<p><span class="math display"> \min_{\text{rank}(B)=r} \|A - B\|_2 = \|A - A_r\|_2 = \sigma_{r+1}. </span></p>
<p>The same holds for <span class="math inline">\|\cdot\|_F</span>, but <span class="math inline">\|A - A_r\|_F = \sqrt{\sigma_{r+1}^2 + \dots + \sigma_{\min (n,m)}^2}</span>.</p>
<section id="proof-1" class="level2">
<h2 class="anchored" data-anchor-id="proof-1">Proof</h2>
<ul>
<li>Since <span class="math inline">\text{rank} (B) = r</span>, it holds <span class="math inline">\text{dim}~\text{ker}~B = n-r</span>.</li>
<li>Hence there exists <span class="math inline">z\not=0</span> such that <span class="math inline">z\in \text{ker}(B) \cap \mathcal{L}(v_1,\dots,v_{r+1})</span> (as <span class="math inline">\text{dim}\{v_1,\dots,v_{r+1}\} = r+1</span>).</li>
<li>Fix <span class="math inline">\|z\| = 1</span>. Therefore,</li>
</ul>
<p><span class="math display"> \|A-B\|_2^2 \geq \|(A-B)z\|_2^2 = \|Az\|_2^2 = \| U\Sigma V^* z\|^2_2= \|\Sigma V^* z\|^2_2 = \sum_{i=1}^{n} \sigma_i^2 (v_i^*z)^2 =\sum_{i=1}^{r+1} \sigma_i^2 (v_i^*z)^2 \geq \sigma_{r+1}^2\sum_{i=1}^{r+1} (v_i^*z)^2 = \sigma_{r+1}^2 </span></p>
<p>as <span class="math inline">\sigma_1\geq \dots \geq \sigma_{r+1}</span> and <span class="math display">\sum_{i=1}^{r+1} (v_i^*z)^2 = \|V^*z\|_2^2 = \|z\|_2^2 = 1.</span></p>
</section>
<section id="main-result-on-low-rank-approximation" class="level2">
<h2 class="anchored" data-anchor-id="main-result-on-low-rank-approximation">Main result on low-rank approximation</h2>
<p><strong>Corollary:</strong> computation of the best rank-<span class="math inline">r</span> approximation is equivalent to setting <span class="math inline">\sigma_{r+1}= 0, \ldots, \sigma_K = 0</span>. The error</p>
<p><span class="math display"> \min_{A_r} \Vert A - A_r \Vert_2 = \sigma_{r+1}, \quad \min_{A_r} \Vert A - A_r \Vert_F = \sqrt{\sigma_{r+1}^2 + \dots + \sigma_{K}^2} </span></p>
<p>that is why it is important to look at the decay of the singular values.</p>
</section>
<section id="computing-svd" class="level2">
<h2 class="anchored" data-anchor-id="computing-svd">Computing SVD</h2>
<ul>
<li><p>Algorithms for the computation of the SVD are tricky and will be discussed later.</p></li>
<li><p>But for numerics, we can use NumPy or JAX or PyTorch already!</p></li>
</ul>
<p>Let us go back to the previous example</p>
<div id="cell-33" class="cell" data-slideshow="{&quot;slide_type&quot;:&quot;slide&quot;}" data-execution_count="3">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Computing matrix rank</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>n <span class="op">=</span> <span class="dv">50</span> </span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> jnp.ones((n, n))</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Rank of the matrix:'</span>, np.linalg.matrix_rank(a))</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> a <span class="op">+</span> <span class="fl">1e-5</span> <span class="op">*</span> np.random.randn(<span class="op">*</span>a.shape)</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Rank of the matrix:'</span>, np.linalg.matrix_rank(b, tol<span class="op">=</span><span class="fl">1e-7</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Rank of the matrix: 1
Rank of the matrix: 49</code></pre>
</div>
</div>
<div id="cell-34" class="cell" data-slideshow="{&quot;slide_type&quot;:&quot;slide&quot;}" data-execution_count="4">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>u, s, v <span class="op">=</span> np.linalg.svd(b) <span class="co">#b = u@jnp.diag(s)@v </span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(s<span class="op">/</span>s[<span class="dv">0</span>])</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(s[<span class="dv">1</span>]<span class="op">/</span>s[<span class="dv">0</span>])</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>r <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>u1 <span class="op">=</span> u[:, :r]</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>s1 <span class="op">=</span> s[:r]</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>v1 <span class="op">=</span> v[:r, :]</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>a1 <span class="op">=</span> u1.dot(np.diag(s1).dot(v1))</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(np.linalg.norm(b <span class="op">-</span> a1, <span class="dv">2</span>)<span class="op">/</span>s[<span class="dv">0</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1.00000000e+00 2.74448832e-09 2.44654918e-09 2.42773562e-09
 2.31264167e-09 2.27689153e-09 2.19991302e-09 2.14396536e-09
 2.11550251e-09 1.97278176e-09 1.94284870e-09 1.89051773e-09
 1.81330587e-09 1.72565526e-09 1.67993428e-09 1.59113590e-09
 1.58090460e-09 1.54788430e-09 1.51371766e-09 1.35601427e-09
 1.29745155e-09 1.28204694e-09 1.24122734e-09 1.16997512e-09
 1.16408528e-09 1.07099869e-09 1.02269543e-09 9.77647860e-10
 9.55021103e-10 8.96594708e-10 8.66479269e-10 8.33647595e-10
 8.09757684e-10 7.82520013e-10 7.40035132e-10 6.93012504e-10
 6.22256571e-10 5.69581513e-10 5.40911549e-10 4.96101659e-10
 4.29921664e-10 3.88697820e-10 3.55032936e-10 2.93775499e-10
 2.44412221e-10 2.10276245e-10 1.34695842e-10 1.19487903e-10
 7.45166628e-11 4.16866804e-11]
2.744488324665868e-09
2.7444883257824676e-09</code></pre>
</div>
</div>
</section>
<section id="separation-of-variables-for-2d-functions" class="level2">
<h2 class="anchored" data-anchor-id="separation-of-variables-for-2d-functions">Separation of variables for 2D functions</h2>
<p>We can use SVD to compute approximations of <strong>function-related</strong> matrices, i.e.&nbsp;the matrices of the form</p>
<p><span class="math display">a_{ij} = f(x_i, y_j),</span></p>
<p>where <span class="math inline">f</span> is a certain function, and <span class="math inline">x_i, \quad i = 1, \ldots, n</span> and <span class="math inline">y_j, \quad j = 1, \ldots, m</span> are some <strong>one-dimensional grids</strong>.</p>
<div id="cell-36" class="cell" data-slideshow="{&quot;slide_type&quot;:&quot;slide&quot;}" data-execution_count="14">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>matplotlib inline</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>plt.rc(<span class="st">"text"</span>, usetex<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>n <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> [[<span class="fl">1.0</span><span class="op">/</span>(i<span class="op">-</span>j<span class="op">+</span><span class="fl">0.5</span>) <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(n)] <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(n)] <span class="co">#Hilbert matrix </span></span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a><span class="co">#a = jnp.ones((n, n)) + 1e-3*jax.random.normal(jax.random.PRNGKey(67575), (n, n))</span></span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> np.array(a)</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>u, s, v <span class="op">=</span> np.linalg.svd(a)</span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(s[<span class="dv">50</span>] <span class="op">-</span> np.pi)</span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a>plt.plot(s[:<span class="dv">30</span>], <span class="st">'x'</span>)</span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a>s</span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a><span class="co">#plt.ylabel(r"$\sigma_i / \sigma_0$", fontsize=24)</span></span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a><span class="co">#plt.xlabel(r"Singular value index, $i$", fontsize=24)</span></span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a><span class="co"># plt.grid(True)</span></span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true" tabindex="-1"></a><span class="co"># plt.xticks(fontsize=26)</span></span>
<span id="cb10-18"><a href="#cb10-18" aria-hidden="true" tabindex="-1"></a><span class="co"># plt.yticks(fontsize=26)</span></span>
<span id="cb10-19"><a href="#cb10-19" aria-hidden="true" tabindex="-1"></a><span class="co"># #We have very good low-rank approximation of it!</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>4.440892098500626e-16</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="14">
<pre><code>array([3.14159265, 3.14159265, 3.14159265, 3.14159265, 3.14159265,
       3.14159265, 3.14159265, 3.14159265, 3.14159265, 3.14159265,
       3.14159265, 3.14159265, 3.14159265, 3.14159265, 3.14159265,
       3.14159265, 3.14159265, 3.14159265, 3.14159265, 3.14159265,
       3.14159265, 3.14159265, 3.14159265, 3.14159265, 3.14159265,
       3.14159265, 3.14159265, 3.14159265, 3.14159265, 3.14159265,
       3.14159265, 3.14159265, 3.14159265, 3.14159265, 3.14159265,
       3.14159265, 3.14159265, 3.14159265, 3.14159265, 3.14159265,
       3.14159265, 3.14159265, 3.14159265, 3.14159265, 3.14159265,
       3.14159265, 3.14159265, 3.14159265, 3.14159265, 3.14159265,
       3.14159265, 3.14159265, 3.14159265, 3.14159265, 3.14159265,
       3.14159265, 3.14159265, 3.14159265, 3.14159265, 3.14159265,
       3.14159265, 3.14159265, 3.14159265, 3.14159265, 3.14159265,
       3.14159265, 3.14159265, 3.14159265, 3.14159265, 3.14159265,
       3.14159265, 3.14159265, 3.14159265, 3.14159265, 3.14159265,
       3.14159265, 3.14159265, 3.14159265, 3.14159265, 3.14159265,
       3.14159265, 3.14159265, 3.14159265, 3.14159265, 3.14159265,
       3.14159265, 3.14159265, 3.14159265, 3.14159263, 3.14159247,
       3.14159137, 3.14158397, 3.14153694, 3.14125447, 3.13966004,
       3.13127783, 3.09092653, 2.91974503, 2.33329   , 0.9473473 ])</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="lecture-4_files/figure-html/cell-6-output-3.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<section id="function-approximation" class="level3">
<h3 class="anchored" data-anchor-id="function-approximation">Function approximation</h3>
<div id="cell-38" class="cell" data-slideshow="{&quot;slide_type&quot;:&quot;slide&quot;}" data-execution_count="4">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>n <span class="op">=</span> <span class="dv">128</span></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>t <span class="op">=</span> np.linspace(<span class="dv">0</span>, <span class="dv">5</span>, n)</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>x, y <span class="op">=</span> np.meshgrid(t, t)</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>f <span class="op">=</span> <span class="fl">1.0</span> <span class="op">/</span> (x <span class="op">+</span> y <span class="op">+</span> <span class="fl">0.01</span>) <span class="co"># test your own function. Check 1.0 / (x - y + 0.5)</span></span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>u, s, v <span class="op">=</span> np.linalg.svd(f, full_matrices<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>r <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>u <span class="op">=</span> u[:, :r]</span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a>s <span class="op">=</span> s[:r]</span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a>v <span class="op">=</span> v[:r, :] <span class="co"># Mind the transpose here!</span></span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a>fappr <span class="op">=</span> (u <span class="op">*</span> s[<span class="va">None</span>, :]) <span class="op">@</span> v</span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a>er <span class="op">=</span> np.linalg.norm(fappr <span class="op">-</span> f, <span class="st">'fro'</span>) <span class="op">/</span> np.linalg.norm(f, <span class="st">'fro'</span>)</span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(er)</span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a>plt.semilogy(s<span class="op">/</span>s[<span class="dv">0</span>])</span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a><span class="co">#plt.ylabel(r"$\sigma_i / \sigma_0$", fontsize=24)</span></span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a><span class="co">#plt.xlabel(r"Singular value index, $i$", fontsize=24)</span></span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a><span class="co">#plt.grid(True)</span></span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a><span class="co">#plt.xticks(fontsize=26)</span></span>
<span id="cb13-20"><a href="#cb13-20" aria-hidden="true" tabindex="-1"></a><span class="co">#plt.yticks(fontsize=26)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>1.800487035360937e-07</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="lecture-4_files/figure-html/cell-7-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="and-3d-plots" class="level2">
<h2 class="anchored" data-anchor-id="and-3d-plots">And 3d plots‚Ä¶</h2>
<div id="cell-41" class="cell" data-slideshow="{&quot;slide_type&quot;:&quot;slide&quot;}" data-execution_count="3">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> mpl_toolkits.mplot3d <span class="im">import</span> Axes3D</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a><span class="co"># plt.xkcd()</span></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>fig <span class="op">=</span> plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">5</span>))</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>ax <span class="op">=</span> fig.add_subplot(<span class="dv">121</span>, projection<span class="op">=</span><span class="st">'3d'</span>)</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>ax.plot_surface(x, y, f)</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>ax.set_title(<span class="st">'Original function'</span>)</span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>ax <span class="op">=</span> fig.add_subplot(<span class="dv">122</span>, projection<span class="op">=</span><span class="st">'3d'</span>)</span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a>ax.plot_surface(x, y, fappr <span class="op">-</span> f)</span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a>ax.set_title(<span class="st">'Approximation error with rank=</span><span class="sc">%d</span><span class="st">, err=</span><span class="sc">%3.1e</span><span class="st">'</span> <span class="op">%</span> (r, er))</span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a>fig.subplots_adjust()</span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a>fig.tight_layout()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="lecture-4_files/figure-html/cell-9-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="singular-values-of-a-random-gaussian-matrix" class="level2">
<h2 class="anchored" data-anchor-id="singular-values-of-a-random-gaussian-matrix">Singular values of a random Gaussian matrix</h2>
<p>What is the singular value decay of a random matrix?</p>
<div id="cell-43" class="cell" data-slideshow="{&quot;slide_type&quot;:&quot;slide&quot;}" data-execution_count="22">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>n <span class="op">=</span> <span class="dv">1000</span></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> jax.random.normal(jax.random.PRNGKey(<span class="dv">244747</span>), (n, n))</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>u, s, v <span class="op">=</span> jnp.linalg.svd(a)</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>plt.semilogy(s<span class="op">/</span>s[<span class="dv">0</span>])</span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="vs">r"$\sigma_i / \sigma_0$"</span>, fontsize<span class="op">=</span><span class="dv">24</span>)</span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="vs">r"Singular value index, $i$"</span>, fontsize<span class="op">=</span><span class="dv">24</span>)</span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a>plt.xticks(fontsize<span class="op">=</span><span class="dv">26</span>)</span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a>plt.yticks(fontsize<span class="op">=</span><span class="dv">26</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="22">
<pre><code>(array([1.e-06, 1.e-05, 1.e-04, 1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01,
        1.e+02]),
 [Text(0, 1e-06, '$\\mathdefault{10^{-6}}$'),
  Text(0, 1e-05, '$\\mathdefault{10^{-5}}$'),
  Text(0, 0.0001, '$\\mathdefault{10^{-4}}$'),
  Text(0, 0.001, '$\\mathdefault{10^{-3}}$'),
  Text(0, 0.01, '$\\mathdefault{10^{-2}}$'),
  Text(0, 0.1, '$\\mathdefault{10^{-1}}$'),
  Text(0, 1.0, '$\\mathdefault{10^{0}}$'),
  Text(0, 10.0, '$\\mathdefault{10^{1}}$'),
  Text(0, 100.0, '$\\mathdefault{10^{2}}$')])</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="lecture-4_files/figure-html/cell-10-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="linear-factor-analysis-low-rank" class="level2">
<h2 class="anchored" data-anchor-id="linear-factor-analysis-low-rank">Linear factor analysis &amp; low-rank</h2>
<p>Consider a linear factor model,</p>
<p><span class="math display">y = Ax, </span></p>
<p>where <span class="math inline">y</span> is a vector of length <span class="math inline">n</span>, and <span class="math inline">x</span> is a vector of length <span class="math inline">r</span>.<br>
The data is organized as samples: we observe vectors</p>
<p><span class="math display">y_1, \ldots, y_T,</span></p>
<p>but do not know matrix <span class="math inline">A</span>, then the factor model can be written as</p>
<p><span class="math display">
  Y = AX,
</span></p>
<p>where <span class="math inline">Y</span> is <span class="math inline">n \times T</span>, <span class="math inline">A</span> is <span class="math inline">n \times r</span> and <span class="math inline">X</span> is <span class="math inline">r \times T</span>.</p>
<ul>
<li>This is exactly a rank-<span class="math inline">r</span> model: it tells us that the vectors lie in a small subspace.</li>
<li>We also can use SVD to recover this subspace (but not the independent components).</li>
<li>Principal component analysis can be done by SVD, checkout the implementation in <a href="https://github.com/scikit-learn/scikit-learn/blob/0d378913be6d7e485b792ea36e9268be31ed52d0/sklearn/decomposition/_pca.py#L465">sklearn package</a>.</li>
</ul>
</section>
<section id="applications-of-svd" class="level2">
<h2 class="anchored" data-anchor-id="applications-of-svd">Applications of SVD</h2>
<ul>
<li><p>SVD is extremely important in computational science and engineering.</p></li>
<li><p>It has many names: Principal component analysis, Proper Orthogonal Decomposition, Empirical Orthogonal Functions</p></li>
<li><p>Now we will consider compression of <strong>dense</strong> matrix and active subspaces method</p></li>
</ul>
</section>
<section id="dense-matrix-compression" class="level2">
<h2 class="anchored" data-anchor-id="dense-matrix-compression">Dense matrix compression</h2>
<p>Dense matrices typically require <span class="math inline">N^2</span> elements to be stored. A rank-<span class="math inline">r</span> approximation can reduces this number to <span class="math inline">\mathcal{O}(Nr)</span></p>
<div id="cell-47" class="cell" data-slideshow="{&quot;slide_type&quot;:&quot;slide&quot;}" data-execution_count="26">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>matplotlib inline</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>n <span class="op">=</span> <span class="dv">256</span></span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> [[<span class="fl">1.0</span><span class="op">/</span>(i <span class="op">-</span> j <span class="op">+</span> <span class="fl">0.5</span>) <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(n)] <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(n)]</span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> np.array(a)</span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a><span class="co">#u, s, v = np.linalg.svd(a)</span></span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a>u, s, v <span class="op">=</span> jnp.linalg.svd(a[n<span class="op">//</span><span class="dv">2</span>:, :n<span class="op">//</span><span class="dv">2</span>])</span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a>plt.semilogy(s<span class="op">/</span>s[<span class="dv">0</span>])</span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="vs">r"$\sigma_i / \sigma_0$"</span>, fontsize<span class="op">=</span><span class="dv">24</span>)</span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="vs">r"Singular value index, $i$"</span>, fontsize<span class="op">=</span><span class="dv">24</span>)</span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a>plt.xticks(fontsize<span class="op">=</span><span class="dv">26</span>)</span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true" tabindex="-1"></a>plt.yticks(fontsize<span class="op">=</span><span class="dv">26</span>)</span>
<span id="cb18-16"><a href="#cb18-16" aria-hidden="true" tabindex="-1"></a><span class="co">#s[0] - jnp.pi</span></span>
<span id="cb18-17"><a href="#cb18-17" aria-hidden="true" tabindex="-1"></a><span class="co">#u, s, v = jnp.linalg.svd(a[:128:, :128])</span></span>
<span id="cb18-18"><a href="#cb18-18" aria-hidden="true" tabindex="-1"></a><span class="co">#print(s[0]-jnp.pi)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="26">
<pre><code>DeviceArray(-0.3372376, dtype=float32)</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="lecture-4_files/figure-html/cell-11-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="compression-of-parameters-in-fully-connected-neural-networs" class="level2">
<h2 class="anchored" data-anchor-id="compression-of-parameters-in-fully-connected-neural-networs">Compression of parameters in fully-connected neural networs</h2>
<ul>
<li>One of the main building blocks of the modern deep neural networks is <strong>fully-connected layer</strong> a.k.a. <strong>linear layer</strong></li>
<li>This layer implements the action of a linear function to an input vector: <span class="math inline">f(x) = Wx + b</span>, where <span class="math inline">W</span> is a trainable matrix and <span class="math inline">b</span> is a trainable bias vector</li>
<li>Both <span class="math inline">W</span> and <span class="math inline">b</span> are updated during training of the network according to some optimization method, i.e.&nbsp;SGD, Adam, etc‚Ä¶</li>
<li>However, the storing of the trained optimal parameters (<span class="math inline">W</span> and <span class="math inline">b</span>) can be <strong>prohibitive</strong> if you want to port your trained network to the device, where memory is limited</li>
<li>As a possible recipe, you can <strong>compress</strong> matrices <span class="math inline">W_i</span> from the <span class="math inline">i</span>-th linear layer with the truncated SVD based on the singular values!</li>
<li>What do you get after such apprioximation of <span class="math inline">W</span>?
<ul>
<li>memory efficient storage</li>
<li>faster inference</li>
<li>moderate degradation of the accuracy in solving the target task, i.e.&nbsp;image classification</li>
</ul></li>
</ul>
</section>
<section id="active-subspaces" class="level2">
<h2 class="anchored" data-anchor-id="active-subspaces">Active Subspaces</h2>
<ul>
<li><p>Suppose, we are given a function <span class="math inline">f(x), \ x \in \mathcal{X} \subseteq \mathbb{R}^{n}</span> and want find its low-dimensional parametrization. Here <span class="math inline">\mathcal{X}</span> is the domain of <span class="math inline">f(x)</span>.</p></li>
<li><p>Informally, we are searching for the directions in which a <span class="math inline">f(x)</span> changes a lot on average and for the directions in which <span class="math inline">f(x)</span> is almost constant.</p></li>
<li><p>Formally, we assume that there is a matrix <span class="math inline">W \in \mathbb{R}^{r \times n}</span> and a function <span class="math inline">g: \mathbb{R^r} \to \mathbb{R}</span>, such that for every <span class="math inline">x \in \mathcal{X}</span></p></li>
</ul>
<p><span class="math display">
f(x)
\approx
g(W x).
</span></p>
<section id="how-to-discover-active-subspaces" class="level3">
<h3 class="anchored" data-anchor-id="how-to-discover-active-subspaces">How to discover Active Subspaces:</h3>
<p><u>Using SVD</u>: 1. Choose <span class="math inline">m</span>, the number of estimations. This hyperparameter stands for the number of Monte Carlo estimations. The larger <span class="math inline">m</span>, the more accurate the result is. 2. Draw samples <span class="math inline">\lbrace x_i \rbrace_{i = 1}^{m}</span> from <span class="math inline">\mathcal{X}</span> (according to some prior probability density function) 3. For each <span class="math inline">x_i</span> compute <span class="math inline">\nabla f(x_i)</span> 4. Compute the SVD of the matrix</p>
<p><span class="math display">
G
    :=
\dfrac{1}{\sqrt{m}}
\begin{bmatrix}
\nabla f(x_1) &amp; \nabla f(x_2) &amp; \ldots &amp; \nabla f(x_m)
\end{bmatrix}
    \approx
U \Sigma V^\top.
</span></p>
<ol start="5" type="1">
<li>Estimate the rank of <span class="math inline">G \approx U_r \Sigma_r V_r^\top</span>. The rank <span class="math inline">r</span> of the matrix <span class="math inline">G</span> is the dimensionality of the active subspace.</li>
<li>Low-dimensional vectors are estimated as <span class="math inline">x_{\text{AS}} = U_r^\top x</span>.</li>
</ol>
<p>For further details, look into the book <a href="https://epubs.siam.org/doi/book/10.1137/1.9781611973860">‚ÄûActive Subspaces: Emerging Ideas in Dimension Reduction for Parameter Studies‚Äú (2015) by Paul Constantine</a>.</p>
</section>
</section>
<section id="take-home-message" class="level2">
<h2 class="anchored" data-anchor-id="take-home-message">Take home message</h2>
<ul>
<li>Matrix rank definition</li>
<li>Skeleton approximation and dyadic representation of a rank-<span class="math inline">r</span> matrix</li>
<li>Singular value decomposition and Eckart-Young theorem</li>
<li>Three applications of SVD (linear factor analysis, dense matrix compression, active subspaces).</li>
</ul>
</section>
<section id="next-lecture" class="level2">
<h2 class="anchored" data-anchor-id="next-lecture">Next lecture</h2>
<ul>
<li>Linear systems</li>
<li>Inverse matrix</li>
<li>Condition number</li>
<li>Linear least squares</li>
<li>Pseudoinverse</li>
</ul>
<section id="questions" class="level5">
<h5 class="anchored" data-anchor-id="questions">Questions?</h5>
<div id="cell-54" class="cell" data-slideshow="{&quot;slide_type&quot;:&quot;skip&quot;}" data-execution_count="12">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> IPython.core.display <span class="im">import</span> HTML</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> css_styling():</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>    styles <span class="op">=</span> <span class="bu">open</span>(<span class="st">"../styles/custom.css"</span>, <span class="st">"r"</span>).read()</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> HTML(styles)</span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>css_styling()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="12">
<link href="http://fonts.googleapis.com/css?family=Fenix" rel="stylesheet" type="text/css">
<link href="http://fonts.googleapis.com/css?family=Alegreya+Sans:100,300,400,500,700,800,900,100italic,300italic,400italic,500italic,700italic,800italic,900italic" rel="stylesheet" type="text/css">
<link href="http://fonts.googleapis.com/css?family=Source+Code+Pro:300,400" rel="stylesheet" type="text/css">
<style>
    @font-face {
        font-family: "Computer Modern";
        src: url('http://mirrors.ctan.org/fonts/cm-unicode/fonts/otf/cmunss.otf');
    }
    div.cell{
        /*width:80%;*/
        /*margin-left:auto !important;
        margin-right:auto;*/
    }
    h1 {
        font-family: 'Alegreya Sans', sans-serif;
    }
    h2 {
        font-family: 'Fenix', serif;
    }
    h3{
        font-family: 'Fenix', serif;
        margin-top:12px;
        margin-bottom: 3px;
       }
    h4{
        font-family: 'Fenix', serif;
       }
    h5 {
        font-family: 'Alegreya Sans', sans-serif;
    }      
    div.text_cell_render{
        font-family: 'Alegreya Sans',Computer Modern, "Helvetica Neue", Arial, Helvetica, Geneva, sans-serif;
        line-height: 1.2;
        font-size: 120%;
        /*width:70%;*/
        /*margin-left:auto;*/
        margin-right:auto;
    }
    .CodeMirror{
            font-family: "Source Code Pro";
            font-size: 90%;
    }
/*    .prompt{
        display: None;
    }*/
    .text_cell_render h1 {
        font-weight: 200;
        font-size: 50pt;
        line-height: 110%;
        color:#CD2305;
        margin-bottom: 0.5em;
        margin-top: 0.5em;
        display: block;
    }   
    .text_cell_render h5 {
        font-weight: 300;
        font-size: 16pt;
        color: #CD2305;
        font-style: italic;
        margin-bottom: .5em;
        margin-top: 0.5em;
        display: block;
    }
    
    li {
        line-height: 110%;
    }
    .warning{
        color: rgb( 240, 20, 20 )
        }  

</style>

<script>
    MathJax.Hub.Config({
                        TeX: {
                           extensions: ["AMSmath.js"]
                           },
                tex2jax: {
                    inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                    displayMath: [ ['$$','$$'], ["\\[","\\]"] ]
                },
                displayAlign: 'center', // Change this to 'center' to center equations.
                "HTML-CSS": {
                    styles: {'.MathJax_Display': {"margin": 4}}
                }
        });
</script>
</div>
</div>


</section>
</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "Óßã";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/nla360\.fmin\.xyz");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
          // target, if specified
          link.setAttribute("target", "_blank");
          if (link.getAttribute("rel") === null) {
            link.setAttribute("rel", "noopener");
          }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




<footer class="footer"><div class="nav-footer"><div class="nav-footer-center"><div class="toc-actions"><ul><li><a href="https://github.dev/MerkulovDaniil/nla360/blob/main/lectures/lecture-4/lecture-4.ipynb" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li></ul></div></div></div></footer></body></html>