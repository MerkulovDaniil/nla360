<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.45">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Lecture 9: Randomized linear algebra</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../favicon.svg" rel="icon" type="image/svg+xml">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/copy-tex.min.js" integrity="sha384-ww/583aHhxWkz5DEVn6OKtNiIaLi2iBRNZXfJRiY1Ai7tnJ9UXpEsyvOITVpTl4A" crossorigin="anonymous"></script>

  <script>window.backupDefine = window.define; window.define = undefined;</script><script src="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css">

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<meta property="og:title" content="Lecture 9: Randomized linear algebra">
<meta property="og:description" content="">
<meta name="twitter:title" content="Lecture 9: Randomized linear algebra">
<meta name="twitter:description" content="">
<meta name="twitter:card" content="summary">
</head>

<body class="nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../../logo.svg" alt="nla360.fmin.xyz" class="navbar-logo">
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../program.html"> 
<span class="menu-text">üöÄ –ú–∞—Ç–µ—Ä–∏–∞–ª—ã</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../projects.html"> 
<span class="menu-text">üìΩÔ∏è –ü—Ä–æ–µ–∫—Ç—ã</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools tools-wide">
    <a href="https://github.com/MerkulovDaniil/nla360" title="" class="quarto-navigation-tool px-1" aria-label=""><i class="bi bi-github"></i></a>
    <a href="https://www.youtube.com/@fmin" title="" class="quarto-navigation-tool px-1" aria-label=""><i class="bi bi-youtube"></i></a>
    <a href="https://t.me/nla360" title="" class="quarto-navigation-tool px-1" aria-label=""><i class="bi bi-telegram"></i></a>
    <a href="" title="" class="quarto-navigation-tool px-1" aria-label=""><i class="bi bi-table"></i></a>
    <a href="https://fmin.xyz" title="" class="quarto-navigation-tool px-1" aria-label=""><i class="bi bi-gem"></i></a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header">
</header>


<section id="brief-recap-of-the-previous-lecture" class="level2">
<h2 class="anchored" data-anchor-id="brief-recap-of-the-previous-lecture">Brief recap of the previous lecture</h2>
<p>SVD and algorithms for its computations: divide-and-conquer, QR, Jacobi, bisection.</p>
</section>
<section id="todays-lecture" class="level2">
<h2 class="anchored" data-anchor-id="todays-lecture">Todays lecture</h2>
<p>Today, we will do a brief dive into the randomized NLA.</p>
<p>A good read is (https://arxiv.org/pdf/2002.01387.pdf)</p>
</section>
<section id="random-numbers" class="level2">
<h2 class="anchored" data-anchor-id="random-numbers">Random numbers</h2>
<p>All the computations that we considered up to today were <strong>deterministic</strong>.</p>
<p>However, reduction of complexity can be done by using randomized (stochastic) computation.</p>
<p>Example: randomized matrix multiplication.</p>
</section>
<section id="checking-matrix-equality" class="level2">
<h2 class="anchored" data-anchor-id="checking-matrix-equality">Checking matrix equality</h2>
<p>We can check, if $ A B = C$ in <span class="math inline">\mathcal{O}(n^2)</span> operations.</p>
<p>How?</p>
</section>
<section id="freivalds-algorithm" class="level2">
<h2 class="anchored" data-anchor-id="freivalds-algorithm"><a href="https://en.wikipedia.org/wiki/Freivalds%27_algorithm">Freivalds algorithm</a></h2>
<p>Checks by multiplying by random vectors!</p>
<p>Complexity is <span class="math inline">k n^2</span>, probability is of failure is <span class="math inline">\frac{1}{2^k}</span>.</p>
</section>
<section id="matrix-multiplication" class="level2">
<h2 class="anchored" data-anchor-id="matrix-multiplication">Matrix multiplication</h2>
<p>But can we multiply matrices faster using randomization ideas?</p>
</section>
<section id="randomized-matrix-multiplication" class="level2">
<h2 class="anchored" data-anchor-id="randomized-matrix-multiplication">Randomized matrix multiplication</h2>
<ul>
<li>We know that matrix multiplication <span class="math inline">AB</span> costs <span class="math inline">O(mnp)</span> for matrices <span class="math inline">m \times p</span> and <span class="math inline">p \times n</span></li>
<li>We can construct approximation of this product by sampling rows and columns of the multipliers</li>
</ul>
<p><strong>Q:</strong> how to sample them?</p>
<p><strong>A:</strong> generate probabilities from their norms!</p>
<ul>
<li>So the final approximation expression</li>
</ul>
<p><span class="math display"> AB \approx \sum_{t=1}^k \frac{1}{kp_{i_t}} A^{(i_t)} B_{(i_t)}, </span></p>
<p>where <span class="math inline">A^{(i_t)}</span> is a column of <span class="math inline">A</span> and <span class="math inline">B_{(i_t)}</span> is a row of <span class="math inline">B</span></p>
<ul>
<li>Complexity reduction from <span class="math inline">O(mnp)</span> to <span class="math inline">O(mnk)</span></li>
</ul>
<div id="cell-9" class="cell" data-slideshow="{&quot;slide_type&quot;:&quot;slide&quot;}" data-execution_count="52">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>n <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>p <span class="op">=</span> <span class="dv">10000</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>m <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>A <span class="op">=</span> np.random.randn(n, p)</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>B <span class="op">=</span> np.random.randn(p, m)</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>C <span class="op">=</span> A <span class="op">@</span> A.T</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> randomized_matmul(A, B, k):</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>    p1 <span class="op">=</span> A.shape[<span class="dv">1</span>]</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>    p <span class="op">=</span> np.linalg.norm(A, axis<span class="op">=</span><span class="dv">0</span>) <span class="op">*</span> np.linalg.norm(B, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>    p <span class="op">=</span> p</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>    p <span class="op">=</span> p.ravel() <span class="op">/</span> p.<span class="bu">sum</span>()</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>    n <span class="op">=</span> A.shape[<span class="dv">1</span>]</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>    p <span class="op">=</span> np.ones(p1)</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>    p <span class="op">=</span> p<span class="op">/</span>p.<span class="bu">sum</span>()</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>    idx <span class="op">=</span> np.random.choice(np.arange(n), (k,), <span class="va">False</span>, p)</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>    <span class="co">#d = 1 / np.sqrt(k * p[idx])</span></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>    d <span class="op">=</span> <span class="fl">1.0</span><span class="op">/</span>np.sqrt(k)<span class="co">#np.sqrt(p1)/np.sqrt(k*p[idx])</span></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>    A_sketched <span class="op">=</span> A[:, idx]<span class="op">*</span>np.sqrt(p1)<span class="op">/</span>np.sqrt(k)<span class="co">#* d[None, :]</span></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>    B_sketched <span class="op">=</span> B[idx, :]<span class="op">*</span>np.sqrt(p1)<span class="op">/</span>np.sqrt(k) <span class="co">#* d[:, None]</span></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>    C <span class="op">=</span> A_sketched <span class="op">@</span> B_sketched</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(d)</span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> C</span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> randomized_matmul_topk(A, B, K):</span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>    norm_mult <span class="op">=</span> np.linalg.norm(A,axis<span class="op">=</span><span class="dv">0</span>) <span class="op">*</span> np.linalg.norm(B,axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a>    top_k_idx <span class="op">=</span> np.sort(np.argsort(norm_mult)[::<span class="op">-</span><span class="dv">1</span>][:K])</span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a>    A_top_k_cols <span class="op">=</span> A[:, top_k_idx]</span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a>    B_top_k_rows <span class="op">=</span> B[top_k_idx, :]</span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a>    C_approx <span class="op">=</span> A_top_k_cols <span class="op">@</span> B_top_k_rows</span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> C_approx</span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a>num_items <span class="op">=</span> <span class="dv">3000</span></span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a>C_appr_samples <span class="op">=</span> randomized_matmul(A, B, num_items)</span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(C_appr_samples, <span class="st">'appr'</span>)</span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(C, <span class="st">'true'</span>)</span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a>C_appr_topk <span class="op">=</span> randomized_matmul_topk(A, B, num_items)</span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(np.linalg.norm(C_appr_topk <span class="op">-</span> C, <span class="dv">2</span>) <span class="op">/</span> np.linalg.norm(C, <span class="dv">2</span>))</span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(np.linalg.norm(C_appr_samples <span class="op">-</span> C, <span class="dv">2</span>) <span class="op">/</span> np.linalg.norm(C, <span class="dv">2</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>0.018257418583505537
[[-209.68265641]] appr
[[10065.73675927]] true
1.012091041179466
1.020831327246555</code></pre>
</div>
</div>
</section>
<section id="approximation-error" class="level2">
<h2 class="anchored" data-anchor-id="approximation-error">Approximation error</h2>
<p><span class="math display"> \mathbb{E} [\|AB - CR\|^2_F] = \frac{1}{k} \left(\sum_{i=1}^n \| A^{(i)} \|_2 \| B_{(i)} \|_2\right)^2   - \frac{1}{k}\|AB\|_F^2 </span></p>
<ul>
<li><p>Other sampling probabilities are possible</p></li>
<li><p>Use approximation <span class="math display"> AB \approx ASD(SD)^\top B  = ACC^{\top}B</span> can replace sampling and scaling with another matrix that</p>
<ul>
<li>reduces the dimension</li>
<li>sufficiently accurately approximates</li>
</ul></li>
</ul>
<p><strong>Q:</strong> what matrices can be used?</p>
<section id="stochastic-trace-estimator" class="level3">
<h3 class="anchored" data-anchor-id="stochastic-trace-estimator">Stochastic trace estimator</h3>
<p>Many problems can be written in the form of the trace estimation:</p>
<p><span class="math display">\mathrm{Tr}(A) = \sum_{i} A_{ii}.</span></p>
<p>Can we compute the trace of the matrix if we only have access to matrix-by-vector products?</p>
</section>
</section>
<section id="two-estimators" class="level2">
<h2 class="anchored" data-anchor-id="two-estimators">Two estimators</h2>
<p>The randomized trace estimators can be computed from the following formula:</p>
<p><span class="math display">\mathrm{Tr}(A) = E_w w^* A w, \quad E ww^* = 1</span></p>
<p>In order to sample, we pick <span class="math inline">k</span> independent samples of <span class="math inline">w_k</span>, get random variable <span class="math inline">X_k</span> and average the results.</p>
<p><strong>Girard trace estimator</strong>: Sample <span class="math inline">w \sim N(0, 1)</span></p>
<p>Then, <span class="math inline">\mathrm{Var} X_k = \frac{2}{k} \sum_{i, j=1}^n \vert A_{ij} \vert^2 = \frac{2}{k} \Vert A \Vert^2_F</span></p>
<p><strong>Hutchinson trace estimator</strong>: Let <span class="math inline">w</span> be a Rademacher random vector (i.e., elements are sampled from the uniform distribution.</p>
<p>It gives the minimal variance estimator.</p>
</section>
<section id="intdim" class="level2">
<h2 class="anchored" data-anchor-id="intdim">Intdim</h2>
<p>The variance of the trace can be estimated in terms of <strong>intrinsic dimension</strong> (intdim) for symmetric positive definite matrices.</p>
<p>It is defined as <span class="math inline">\mathrm{intdim}(A) = \frac{\mathrm{Tr}(A)}{\Vert A \Vert_F}</span>. It is easy to show that</p>
<p><span class="math display">1 \leq \mathrm{intdim}(A) \leq ?.</span></p>
<p>Then, the probability of the large deviation can be estimated as</p>
<p><span class="math display">P( \vert \overline{X}_k - \mathrm{Tr}(A) \vert \geq t \mathrm{Tr}(A)) \leq \frac{2}{k \mathrm{intdim}(A) t^2}</span></p>
</section>
<section id="better-bounds-for-spd-matrices" class="level2">
<h2 class="anchored" data-anchor-id="better-bounds-for-spd-matrices">Better bounds for SPD matrices</h2>
<p>If <span class="math inline">A</span> is SPD, then</p>
<p><span class="math display">P(\overline{X}_k \geq \tau \mathrm{Tr}(A) ) \leq \exp\left(-1/2 \mathrm{intdim}(A) (\sqrt{\tau} - 1)^2)\right) </span></p>
<p>Similar inequality holds for the lower bound.</p>
<p>This estimate is much better.</p>
<p>An interesting (and often mislooked) property of stochastic estimator is that it comes with a stochastic variance estimate (from samples!)</p>
<p>Warning: we still need <span class="math inline">\varepsilon^{-2}</span> samples to get to the accuracy <span class="math inline">\varepsilon</span> when using independent samples.</p>
<section id="distances-between-languages-original-paper" class="level3">
<h3 class="anchored" data-anchor-id="distances-between-languages-original-paper">Distances between languages (<a href="https://openreview.net/pdf?id=HyebplHYwB">original paper</a>)</h3>
<p><img src="./gw_matexp.png"></p>
</section>
</section>
<section id="where-do-stochastic-methods-also-help" class="level2">
<h2 class="anchored" data-anchor-id="where-do-stochastic-methods-also-help">Where do stochastic methods also help?</h2>
<ul>
<li>SVD</li>
<li>Linear systems</li>
</ul>
</section>
<section id="randomized-svd-halko-et-al-2011" class="level2">
<h2 class="anchored" data-anchor-id="randomized-svd-halko-et-al-2011">Randomized SVD (<a href="https://epubs.siam.org/doi/pdf/10.1137/090771806?casa_token=isi3yX3QdPEAAAAA:j-7Qk87vS0kjKqGMLYeX3xg4QxqqyM8s4wn-XGX-SLOS2BRChFDRTPX-x9Hf7ltfuZYg9xsA0zksw1U">Halko et al, 2011</a>)</h2>
<ul>
<li>Problem statement reminder</li>
</ul>
<p><span class="math display"> A \approx U\Sigma V^\top, </span></p>
<p>where <span class="math inline">A</span> is of size <span class="math inline">m \times n</span>, <span class="math inline">U</span> is of size <span class="math inline">m \times k</span> and <span class="math inline">V</span> is of size <span class="math inline">n \times k</span>.</p>
<ul>
<li><p>We have already known that the complexity of rank-<span class="math inline">k</span> approximation is <span class="math inline">O(mnk)</span></p></li>
<li><p>How can we reduce this complexity?</p></li>
<li><p>Assume we know orthogonal matrix <span class="math inline">Q</span> of size <span class="math inline">m \times k</span> such that</p></li>
</ul>
<p><span class="math display">A \approx Q Q^{\top}A </span></p>
<ul>
<li>In other words, columns of <span class="math inline">Q</span> represent orthogonal basis in the column space of matrix <span class="math inline">A</span></li>
<li>Then the following deterministic steps can give the factors <span class="math inline">U</span>, <span class="math inline">\Sigma</span> and <span class="math inline">V</span> corresponding of SVD of matrix <span class="math inline">A</span>
<ul>
<li>Form <span class="math inline">k \times n</span> matrix <span class="math inline">B = Q^{\top}A</span></li>
<li>Compute SVD of small matrix <span class="math inline">B = \hat{U}\Sigma V^{\top}</span></li>
<li>Update left singular vectors <span class="math inline">U = Q\hat{U}</span></li>
</ul></li>
<li>If <span class="math inline">k \ll \min(m, n)</span> then these steps can be performed fast</li>
<li>If <span class="math inline">Q</span> forms exact basis in column space of <span class="math inline">A</span>, then <span class="math inline">U</span>, <span class="math inline">\Sigma</span> and <span class="math inline">V</span> are also exact!</li>
<li>So, how to compose matrix <span class="math inline">Q</span>?</li>
</ul>
<section id="randomized-approximation-of-basis-in-column-space-of-a" class="level3">
<h3 class="anchored" data-anchor-id="randomized-approximation-of-basis-in-column-space-of-a">Randomized approximation of basis in column space of <span class="math inline">A</span></h3>
<ul>
<li>The main approach
<ul>
<li>Generate <span class="math inline">k + p</span> Gaussian vectors of size <span class="math inline">m</span> and form matrix <span class="math inline">G</span></li>
<li>Compute <span class="math inline">Y = AG</span></li>
<li>Compute QR decomposition of <span class="math inline">Y</span> and use the resulting matrix <span class="math inline">Q</span> as an approximation of the basis</li>
</ul></li>
<li>Parameter <span class="math inline">p</span> is called <strong>oversampling</strong> parameter and is needed to improve approximation of the leading <span class="math inline">k</span> left singular vectors later</li>
<li>Computing of <span class="math inline">Y</span> can be done in parallel</li>
<li>Here we need only matvec function for matrix <span class="math inline">A</span> rather than its elements as a 2D array - black-box concept!</li>
<li>Instead of Gaussian random matrix one can use more structured but still random matrix that can be multiplied by <span class="math inline">A</span> fast</li>
</ul>
<div id="cell-20" class="cell" data-slideshow="{&quot;slide_type&quot;:&quot;slide&quot;}" data-execution_count="4">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>n <span class="op">=</span> <span class="dv">1000</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>k <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>m <span class="op">=</span> <span class="dv">200</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Lowrank matrix</span></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>A <span class="op">=</span> np.random.randn(n, k)</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>B <span class="op">=</span> np.random.randn(k, m)</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>A <span class="op">=</span> A <span class="op">@</span> B</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Random matrix</span></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a><span class="co"># A = np.random.randn(n, m)</span></span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> randomized_svd(A, rank, p):</span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>    m, n <span class="op">=</span> A.shape</span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>    G <span class="op">=</span> np.random.randn(n, rank <span class="op">+</span> p)</span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>    Y <span class="op">=</span> A <span class="op">@</span> G</span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a>    Q, _ <span class="op">=</span> np.linalg.qr(Y)</span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a>    B <span class="op">=</span> Q.T <span class="op">@</span> A</span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a>    u, S, V <span class="op">=</span> np.linalg.svd(B)</span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a>    U <span class="op">=</span> Q <span class="op">@</span> u</span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> U, S, V</span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true" tabindex="-1"></a>rank <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb3-26"><a href="#cb3-26" aria-hidden="true" tabindex="-1"></a>p <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb3-27"><a href="#cb3-27" aria-hidden="true" tabindex="-1"></a>U, S, V <span class="op">=</span> randomized_svd(A, rank, p)</span>
<span id="cb3-28"><a href="#cb3-28" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Error from randomized SVD"</span>, np.linalg.norm(A <span class="op">-</span> U[:, :rank] <span class="op">*</span> S[<span class="va">None</span>, :rank] <span class="op">@</span> V[:rank, :]))</span>
<span id="cb3-29"><a href="#cb3-29" aria-hidden="true" tabindex="-1"></a>plt.semilogy(S[:rank] <span class="op">/</span> S[<span class="dv">0</span>], label<span class="op">=</span><span class="st">"Random SVD"</span>)</span>
<span id="cb3-30"><a href="#cb3-30" aria-hidden="true" tabindex="-1"></a>u, s, v <span class="op">=</span> np.linalg.svd(A)</span>
<span id="cb3-31"><a href="#cb3-31" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Error from exact SVD"</span>, np.linalg.norm(A <span class="op">-</span> u[:, :rank] <span class="op">*</span> s[<span class="va">None</span>, :rank] <span class="op">@</span> v[:rank, :]))</span>
<span id="cb3-32"><a href="#cb3-32" aria-hidden="true" tabindex="-1"></a>plt.semilogy(s[:rank] <span class="op">/</span> s[<span class="dv">0</span>], label<span class="op">=</span><span class="st">"Exact SVD"</span>)</span>
<span id="cb3-33"><a href="#cb3-33" aria-hidden="true" tabindex="-1"></a>plt.legend(fontsize<span class="op">=</span><span class="dv">18</span>)</span>
<span id="cb3-34"><a href="#cb3-34" aria-hidden="true" tabindex="-1"></a>plt.xticks(fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb3-35"><a href="#cb3-35" aria-hidden="true" tabindex="-1"></a>plt.yticks(fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb3-36"><a href="#cb3-36" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"$\sigma_i / \sigma_0$"</span>, fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb3-37"><a href="#cb3-37" aria-hidden="true" tabindex="-1"></a>_ <span class="op">=</span> plt.xlabel(<span class="st">"Index of singular value"</span>, fontsize<span class="op">=</span><span class="dv">16</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Error from randomized SVD 1.7704601563939492e-11
Error from exact SVD 1.195330542835496e-11</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="lecture-9_files/figure-html/cell-3-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="cell-21" class="cell" data-slideshow="{&quot;slide_type&quot;:&quot;slide&quot;}" data-execution_count="2">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> scipy.sparse.linalg <span class="im">as</span> spsplin</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="co"># More details about Facebook package for computing randomized SVD is here: https://research.fb.com/blog/2014/09/fast-randomized-svd/ </span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> fbpca</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>n <span class="op">=</span> <span class="dv">1000</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>m <span class="op">=</span> <span class="dv">200</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>A <span class="op">=</span> np.random.randn(n, m)</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>k <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>p <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>timeit spsplin.svds(A, k<span class="op">=</span>k)</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>timeit randomized_svd(A, k, p)</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>timeit fbpca.pca(A, k<span class="op">=</span>k, raw<span class="op">=</span><span class="va">False</span>) </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>60.5 ms ¬± 11.5 ms per loop (mean ¬± std. dev. of 7 runs, 10 loops each)
8.07 ms ¬± 3.32 ms per loop (mean ¬± std. dev. of 7 runs, 100 loops each)
3.09 ms ¬± 177 ¬µs per loop (mean ¬± std. dev. of 7 runs, 100 loops each)</code></pre>
</div>
</div>
</section>
<section id="convergence-theorem" class="level3">
<h3 class="anchored" data-anchor-id="convergence-theorem">Convergence theorem</h3>
<p>The averaged error of the presented algorithm, where <span class="math inline">k</span> is target rank and <span class="math inline">p</span> is oversampling parameter, is the following - in Frobenius norm</p>
<p><span class="math display"> \mathbb{E}\|A - QQ^{\top}A \|_F \leq \left( 1 + \frac{k}{p-1} \right)^{1/2}\left( \sum_{j=k+1}^{\min(m, n)} \sigma^2_j \right)^{1/2}  </span></p>
<ul>
<li>in spectral norm</li>
</ul>
<p><span class="math display"> \mathbb{E}\|A - QQ^{\top}A \|_2 \leq \left( 1 + \sqrt{\frac{k}{p-1}} \right)\sigma_{k+1} + \frac{e\sqrt{k+p}}{p}\left( \sum_{j=k+1}^{\min(m, n)} \sigma^2_j \right)^{1/2} </span></p>
<p>The expectation is taken w.r.t. random matrix <span class="math inline">G</span> generated in the method described above.</p>
<p>Compare these upper bounds with Eckart-Young theorem. Are these bounds good?</p>
</section>
</section>
<section id="accuracy-enhanced-randomized-svd" class="level2">
<h2 class="anchored" data-anchor-id="accuracy-enhanced-randomized-svd">Accuracy enhanced randomized SVD</h2>
<ul>
<li>Main idea: power iteration</li>
<li>If <span class="math inline">A = U \Sigma V^\top</span>, then $A^{(q)} = (AA<sup>{})</sup>qA = U <sup>{2q+1}V</sup>$, where <span class="math inline">q</span> some small natural number, e.g.&nbsp;1 or 2</li>
<li>Then we sample from <span class="math inline">A^{(q)}</span>, not from <span class="math inline">A</span></li>
</ul>
<p><span class="math display"> Y = (AA^{\top})^qAG \qquad Q, R = \mathtt{qr}(Y) </span></p>
<ul>
<li>The main reason: if singular values of <span class="math inline">A</span> decays slowly, the singular values of <span class="math inline">A^{(q)}</span> will decay faster</li>
</ul>
<div id="cell-24" class="cell" data-slideshow="{&quot;slide_type&quot;:&quot;slide&quot;}" data-execution_count="5">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>n <span class="op">=</span> <span class="dv">1000</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>m <span class="op">=</span> <span class="dv">200</span></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>A <span class="op">=</span> np.random.randn(n, m)</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>s <span class="op">=</span> np.linalg.svd(A, compute_uv<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>Aq <span class="op">=</span> A <span class="op">@</span> A.T <span class="op">@</span> A</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>sq <span class="op">=</span> np.linalg.svd(Aq, compute_uv<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>plt.semilogy(s <span class="op">/</span> s[<span class="dv">0</span>], label<span class="op">=</span><span class="st">"$A$"</span>)</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>plt.semilogy(sq <span class="op">/</span> sq[<span class="dv">0</span>], label<span class="op">=</span><span class="st">"$A^{(1)}$"</span>)</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>plt.legend(fontsize<span class="op">=</span><span class="dv">18</span>)</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>plt.xticks(fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>plt.yticks(fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"$\sigma_i / \sigma_0$"</span>, fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>_ <span class="op">=</span> plt.xlabel(<span class="st">"Index of singular value"</span>, fontsize<span class="op">=</span><span class="dv">16</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="lecture-9_files/figure-html/cell-5-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<section id="loss-of-accuracy-with-rounding-errors" class="level3">
<h3 class="anchored" data-anchor-id="loss-of-accuracy-with-rounding-errors">Loss of accuracy with rounding errors</h3>
<ul>
<li>Compose <span class="math inline">A^{(q)}</span> naively leads to condition number grows and loss of accuracy</li>
</ul>
<p><strong>Q:</strong> how can we battle with this issue?</p>
<p><strong>A:</strong> sequential orthogonalization!</p>
<div id="cell-27" class="cell" data-slideshow="{&quot;slide_type&quot;:&quot;slide&quot;}" data-execution_count="6">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> more_accurate_randomized_svd(A, rank, p, q):</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>    m, n <span class="op">=</span> A.shape</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>    G <span class="op">=</span> np.random.randn(n, rank <span class="op">+</span> p)</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>    Y <span class="op">=</span> A <span class="op">@</span> G</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>    Q, _ <span class="op">=</span> np.linalg.qr(Y)</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(q):</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>        W <span class="op">=</span> A.T <span class="op">@</span> Q</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>        W, _ <span class="op">=</span> np.linalg.qr(W)</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>        Q <span class="op">=</span> A <span class="op">@</span> W</span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>        Q, _ <span class="op">=</span> np.linalg.qr(Q)</span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>    B <span class="op">=</span> Q.T <span class="op">@</span> A</span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>    u, S, V <span class="op">=</span> np.linalg.svd(B)</span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>    U <span class="op">=</span> Q <span class="op">@</span> u</span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> U, S, V</span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a>n <span class="op">=</span> <span class="dv">1000</span></span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a>m <span class="op">=</span> <span class="dv">200</span></span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a>A <span class="op">=</span> np.random.randn(n, m)</span>
<span id="cb8-19"><a href="#cb8-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-20"><a href="#cb8-20" aria-hidden="true" tabindex="-1"></a>rank <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb8-21"><a href="#cb8-21" aria-hidden="true" tabindex="-1"></a>p <span class="op">=</span> <span class="dv">20</span></span>
<span id="cb8-22"><a href="#cb8-22" aria-hidden="true" tabindex="-1"></a>U, S, V <span class="op">=</span> randomized_svd(A, rank, p)</span>
<span id="cb8-23"><a href="#cb8-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Error from randomized SVD"</span>, np.linalg.norm(A <span class="op">-</span> U[:, :rank] <span class="op">*</span> S[<span class="va">None</span>, :rank] <span class="op">@</span> V[:rank, :]))</span>
<span id="cb8-24"><a href="#cb8-24" aria-hidden="true" tabindex="-1"></a>plt.semilogy(S[:rank] <span class="op">/</span> S[<span class="dv">0</span>], label<span class="op">=</span><span class="st">"Random SVD"</span>)</span>
<span id="cb8-25"><a href="#cb8-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-26"><a href="#cb8-26" aria-hidden="true" tabindex="-1"></a>Uq, Sq, Vq <span class="op">=</span> more_accurate_randomized_svd(A, rank, p, <span class="dv">5</span>)</span>
<span id="cb8-27"><a href="#cb8-27" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Error from more accurate randomized SVD"</span>, np.linalg.norm(A <span class="op">-</span> Uq[:, :rank] <span class="op">*</span> Sq[<span class="va">None</span>, :rank] <span class="op">@</span> Vq[:rank, :]))</span>
<span id="cb8-28"><a href="#cb8-28" aria-hidden="true" tabindex="-1"></a>plt.semilogy(Sq[:rank] <span class="op">/</span> Sq[<span class="dv">0</span>], label<span class="op">=</span><span class="st">"Accurate random SVD"</span>)</span>
<span id="cb8-29"><a href="#cb8-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-30"><a href="#cb8-30" aria-hidden="true" tabindex="-1"></a>u, s, v <span class="op">=</span> np.linalg.svd(A)</span>
<span id="cb8-31"><a href="#cb8-31" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Error from exact SVD"</span>, np.linalg.norm(A <span class="op">-</span> u[:, :rank] <span class="op">*</span> s[<span class="va">None</span>, :rank] <span class="op">@</span> v[:rank, :]))</span>
<span id="cb8-32"><a href="#cb8-32" aria-hidden="true" tabindex="-1"></a>plt.semilogy(s[:rank] <span class="op">/</span> s[<span class="dv">0</span>], label<span class="op">=</span><span class="st">"Exact SVD"</span>)</span>
<span id="cb8-33"><a href="#cb8-33" aria-hidden="true" tabindex="-1"></a>plt.legend(fontsize<span class="op">=</span><span class="dv">18</span>)</span>
<span id="cb8-34"><a href="#cb8-34" aria-hidden="true" tabindex="-1"></a>plt.xticks(fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb8-35"><a href="#cb8-35" aria-hidden="true" tabindex="-1"></a>plt.yticks(fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb8-36"><a href="#cb8-36" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"$\sigma_i / \sigma_0$"</span>, fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb8-37"><a href="#cb8-37" aria-hidden="true" tabindex="-1"></a>_ <span class="op">=</span> plt.xlabel(<span class="st">"Index of singular value"</span>, fontsize<span class="op">=</span><span class="dv">16</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Error from randomized SVD 286.99760873015225
Error from more accurate randomized SVD 250.2388642432797
Error from exact SVD 249.3503301291079</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="lecture-9_files/figure-html/cell-6-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="cell-28" class="cell" data-slideshow="{&quot;slide_type&quot;:&quot;slide&quot;}" data-execution_count="7">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>timeit spsplin.svds(A, k<span class="op">=</span>k)</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>timeit fbpca.pca(A, k<span class="op">=</span>k, raw<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>timeit randomized_svd(A, k, p) </span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>timeit more_accurate_randomized_svd(A, k, p, <span class="dv">1</span>)</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>timeit more_accurate_randomized_svd(A, k, p, <span class="dv">2</span>)</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>timeit more_accurate_randomized_svd(A, k, p, <span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>347 ms ¬± 60.1 ms per loop (mean ¬± std. dev. of 7 runs, 1 loop each)
82.3 ms ¬± 6.93 ms per loop (mean ¬± std. dev. of 7 runs, 10 loops each)
68.7 ms ¬± 4.99 ms per loop (mean ¬± std. dev. of 7 runs, 10 loops each)
118 ms ¬± 6.57 ms per loop (mean ¬± std. dev. of 7 runs, 10 loops each)
176 ms ¬± 13.9 ms per loop (mean ¬± std. dev. of 7 runs, 10 loops each)
352 ms ¬± 43.3 ms per loop (mean ¬± std. dev. of 7 runs, 1 loop each)</code></pre>
</div>
</div>
</section>
<section id="convergence-theorem-1" class="level3">
<h3 class="anchored" data-anchor-id="convergence-theorem-1">Convergence theorem</h3>
<p>The presented above method provides the following upper bound</p>
<p><span class="math display"> \mathbb{E}\|A - QQ^{\top}A \|_2 \leq \left[\left( 1 + \sqrt{\frac{k}{p-1}} \right)\sigma^{2q+1}_{k+1} + \frac{e\sqrt{k+p}}{p}\left( \sum_{j=k+1}^{\min(m, n)} \sigma^{2(2q+1)}_j \right)^{1/2}\right]^{1/(2q+1)} </span></p>
<p>Consider the worst case, where no lowrank structure exists in the given matrix.</p>
<p><strong>Q:</strong> what is the degree of suboptimality w.r.t. Eckart-Young theorem?</p>
</section>
<section id="summary-on-randomized-svd" class="level3">
<h3 class="anchored" data-anchor-id="summary-on-randomized-svd">Summary on randomized SVD</h3>
<ul>
<li>Efficient method to get approximate SVD</li>
<li>Simple to implement</li>
<li>It can be extended to one-pass method, where matrix <span class="math inline">A</span> is needed only to construct <span class="math inline">Q</span></li>
<li>It requires only matvec with target matrix</li>
</ul>
</section>
</section>
<section id="kaczmarz-method-to-solve-linear-systems" class="level2">
<h2 class="anchored" data-anchor-id="kaczmarz-method-to-solve-linear-systems">Kaczmarz method to solve linear systems</h2>
<ul>
<li>We have already discussed how to solve overdetermined linear systems <span class="math inline">Ax = f</span> in the least-squares manner
<ul>
<li>pseudoinverse matrix</li>
<li>QR decomposition</li>
</ul></li>
<li>One more approach is based on iterative projections a.k.a. <strong>Kaczmarz method</strong> or <strong>algebraic reconstruction technique</strong> in compoutational tomography domain</li>
<li>Instead of solving all equations, pick one randomly, which reads</li>
</ul>
<p><span class="math display">a^{\top}_i x = f_i,</span></p>
<p>and given an approximation <span class="math inline">x_k</span> try to find <span class="math inline">x_{k+1}</span> as</p>
<p><span class="math display">x_{k+1} = \arg \min_x \frac12 \Vert x - x_k \Vert^2_2, \quad \mbox{s.t.} \quad  a^{\top}_i x = f_i.</span></p>
<ul>
<li>A simple analysis gives</li>
</ul>
<p><span class="math display">x_{k+1} = x_k - \frac{(a_i, x_k) - f_i}{(a_i, a_i)} a_i. </span></p>
<ul>
<li>A cheap update, but the analysis is quite complicated.</li>
<li>You can recognize in this method stochastic gradient descent with specific step size equal to <span class="math inline">\frac{1}{\|a_i\|_2^2}</span> for every sample</li>
</ul>
</section>
<section id="convergence-theorem-2" class="level2">
<h2 class="anchored" data-anchor-id="convergence-theorem-2">Convergence theorem</h2>
<ul>
<li>Assume we generate <span class="math inline">i</span> according to the distribution over the all available indices proportional to norms of the rows, i.e.&nbsp;<span class="math inline">\mathbb{P}[i = k] = \frac{\|a_k\|_2^2}{\| A \|^2_F}</span>. This method is called Randomized Kaczmarz method (RKM)</li>
<li>Why sampling strategy is important here?</li>
<li>Investigation of the best sampling is provided <a href="https://scholar.harvard.edu/files/yuelu/files/randkac_globalsip14.pdf">here</a></li>
<li>If the overdetermined linear system is <strong>consistent</strong>, then</li>
</ul>
<p><span class="math display"> \mathbb{E}[\|x_{k+1} - x^*\|^2_2] \leq \left(1 - \frac{1}{\kappa^2_F(A)}\right) \mathbb{E}[\|x_{k} - x^*\|^2_2], </span></p>
<p>where <span class="math inline">\kappa_F(A) = \frac{\| A \|_F}{\sigma_{\min}(A)}</span> and <span class="math inline">\sigma_{\min}(A)</span> is a minimal non-zero singular value of <span class="math inline">A</span>. This result was presented in (<a href="http://people.eecs.berkeley.edu/~brecht/cs294docs/week1/09.Strohmer.pdf">Strohmer and Vershynin, 2009</a>)</p>
<ul>
<li>If the overdetermined linear system is <strong>inconsistent</strong>, then</li>
</ul>
<p><span class="math display"> \mathbb{E}[\|x_{k+1} - x^*\|^2_2] \leq \left(1 - \frac{1}{\kappa^2_F(A)}\right) \mathbb{E}[\|x_{k} - x^*\|^2_2] + \frac{\|r^*\|_2^2}{\| A \|^2_F}, </span></p>
<p>where <span class="math inline">r^* = Ax^* - f</span></p>
<section id="inconsistent-overdetermined-linear-system" class="level3">
<h3 class="anchored" data-anchor-id="inconsistent-overdetermined-linear-system">Inconsistent overdetermined linear system</h3>
<ul>
<li><p>It was shown in (<a href="https://arxiv.org/pdf/0902.0958.pdf">Needell, 2010</a>) that RKM does not converge to <span class="math inline">A^{\dagger}f</span></p></li>
<li><p>To address this issue Randomized extended Kaczmarz method was proposed in (<a href="https://arxiv.org/pdf/1205.5770.pdf">A Zouzias, N Freris, 2013</a>)</p></li>
<li><p>The main idea is to use two steps of RKM:</p>
<ul>
<li>the first step is for system <span class="math inline">A^\top z = 0</span> starting from <span class="math inline">z_k</span></li>
</ul>
<p><span class="math display"> z^{k+1} = z^{k} - \frac{a^\top_{:, j} z^k}{\| a_{:, j} \|_2^2}a_{:, j}  </span></p>
<ul>
<li>the second step is for system <span class="math inline">Ax = f - z_{k+1}</span> starting from <span class="math inline">x_k</span></li>
</ul>
<p><span class="math display">x^{k+1} = x^k - \frac{a_{i,:}x_k - f_i + z^{k+1}_i}{\|a_{i,:}\|_2^2}a^{\top}_{i,:} </span></p></li>
</ul>
<p>Here <span class="math inline">a_{:, j}</span> denotes the <span class="math inline">j</span>-th column of <span class="math inline">A</span> and <span class="math inline">a_{i, :}</span> denotes the <span class="math inline">i</span>-th row of <span class="math inline">A</span></p>
<ul>
<li>If <span class="math inline">z^0 \in f + \mathrm{range}(A)</span> and <span class="math inline">x^0 \in \mathrm{range}(A^\top)</span>, then REK converges exponentially to <span class="math inline">A^{\dagger}f</span></li>
</ul>
</section>
</section>
<section id="sampling-and-sketching" class="level2">
<h2 class="anchored" data-anchor-id="sampling-and-sketching">Sampling and sketching</h2>
<ul>
<li>Sampling of a particular row can be considered as a particular case of more general approach called <strong>sketching</strong></li>
<li>Idea: replace matrix <span class="math inline">A</span> with another matrix <span class="math inline">SA</span>, where matrix <span class="math inline">SA</span> has significantly smaller number of rows but preserves some important properties of matrix <span class="math inline">A</span></li>
<li>Possible choices:
<ul>
<li>random projection</li>
<li>random row selection</li>
</ul></li>
<li>Example: linear least squares problem <span class="math inline">\|Ax - b\|_2^2 \to \min_x</span> transforms to <span class="math inline">\| (SA)y - Sb \|_2^2 \to \min_y</span> and we expect that <span class="math inline">x \approx y</span></li>
<li><a href="https://pdos.csail.mit.edu/~petar/papers/blendenpik-v1.pdf">Blendenpick</a> solver is based on that idea and outperforms LAPACK routine</li>
<li>More details see in <a href="https://researcher.watson.ibm.com/researcher/files/us-dpwoodru/wNow3.pdf">Sketching as a Tool for Numerical Linear Algebra</a> by D. Woodruff</li>
</ul>
</section>
<section id="coherence" class="level2">
<h2 class="anchored" data-anchor-id="coherence">Coherence</h2>
<p>The key idea is the coherence of the matrix.</p>
<p>Let <span class="math inline">A</span> be <span class="math inline">n \times r</span> and <span class="math inline">U</span> be an orthogonal matrix whose columns form the basis of the column space of <span class="math inline">A</span>.</p>
<p>Then, coherence is defined as</p>
<p><span class="math display">\mu(A) = \max \Vert U_{i, *} \Vert^2</span></p>
<p>Coherence is always smaller than <span class="math inline">1</span> and bigger than <span class="math inline">\frac{r}{n}</span>, it has nothing to do with the condition number.</p>
<p>What does it mean?</p>
</section>
<section id="coherence-1" class="level2">
<h2 class="anchored" data-anchor-id="coherence-1">Coherence</h2>
<p>Small coherence means, that sampling rows uniformly gives a good preconditioner (will be covered later in the course, and why it is important)</p>
<p>One can do <span class="math inline">S A = QR</span>, and look at the condition number of <span class="math inline">AR^{-1}</span>.</p>
<section id="summary-on-randomized-methods-in-solving-linear-systems" class="level3">
<h3 class="anchored" data-anchor-id="summary-on-randomized-methods-in-solving-linear-systems">Summary on randomized methods in solving linear systems</h3>
<ul>
<li>Easy to use family of methods</li>
<li>Especially useful in problems with streaming data</li>
<li>Existing theoretical bounds for convergence</li>
<li>Many interpretations in different domains (SGD in deep learning, ART in computational tomography)</li>
</ul>
</section>
<section id="summary-on-randomized-matmul" class="level3">
<h3 class="anchored" data-anchor-id="summary-on-randomized-matmul">Summary on randomized matmul</h3>
<ul>
<li>Simple method to get approximation of result</li>
<li>Can be used if the high accuracy is not crucial</li>
<li>Especially useful for large dense matrices</li>
</ul>
</section>
</section>
<section id="next-lecture" class="level2">
<h2 class="anchored" data-anchor-id="next-lecture">Next lecture</h2>
<ul>
<li>We start <strong>sparse and/or structured</strong> NLA.</li>
</ul>
</section>
<section id="questions" class="level1">
<h1>Questions?</h1>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "Óßã";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
          // target, if specified
          link.setAttribute("target", "_blank");
          if (link.getAttribute("rel") === null) {
            link.setAttribute("rel", "noopener");
          }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




<footer class="footer"><div class="nav-footer"><div class="nav-footer-center"><div class="toc-actions"><ul><li><a href="https://github.dev/MerkulovDaniil/nla360/blob/main/lectures/lecture-9/lecture-9.ipynb" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li></ul></div></div></div></footer></body></html>